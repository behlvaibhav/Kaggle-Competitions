{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion Mnist with feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lots of Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build predictive models in Python we use a set of libraries that are imported here. In particular **pandas** and **sklearn** are particularly important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import display, HTML, Image\n",
    "import io\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "from scipy.misc import toimage\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a data sampling rate for speeding up testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a dictionary to store simple model perofrmance comparions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_accuracy_comparisons = dict()\n",
    "model_valid_accuracy_comparisons = dict()\n",
    "model_tuned_params_list = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53309</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48366</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23101</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38653</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "53309      5       0       0       0       0       0       0       0       0   \n",
       "48366      3       0       0       0       0       0       0       0       0   \n",
       "23101      8       0       0       0       0       0       0       0       0   \n",
       "9417       9       0       0       0       0       0       0       0       0   \n",
       "38653      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "53309       0  ...         0         0         0         0         0   \n",
       "48366       0  ...        78         0         0         1         0   \n",
       "23101       0  ...         0         0         0         0         0   \n",
       "9417        0  ...         0         0         0         0         0   \n",
       "38653       0  ...         0         2         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "53309         0         0         0         0         0  \n",
       "48366         0         0         0         0         0  \n",
       "23101         0         0         0         0         0  \n",
       "9417          0         0         0         0         0  \n",
       "38653         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the distribution of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    626\n",
       "9    621\n",
       "5    614\n",
       "4    614\n",
       "2    600\n",
       "0    600\n",
       "8    593\n",
       "3    592\n",
       "7    582\n",
       "6    558\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6000.00000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.480500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>0.348667</td>\n",
       "      <td>0.730833</td>\n",
       "      <td>1.840167</td>\n",
       "      <td>5.293500</td>\n",
       "      <td>...</td>\n",
       "      <td>33.29600</td>\n",
       "      <td>22.255167</td>\n",
       "      <td>16.250167</td>\n",
       "      <td>17.856667</td>\n",
       "      <td>23.363667</td>\n",
       "      <td>18.388500</td>\n",
       "      <td>9.272833</td>\n",
       "      <td>3.306833</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.061667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.885193</td>\n",
       "      <td>0.181198</td>\n",
       "      <td>0.140790</td>\n",
       "      <td>0.514465</td>\n",
       "      <td>3.275865</td>\n",
       "      <td>3.793491</td>\n",
       "      <td>5.000393</td>\n",
       "      <td>7.789619</td>\n",
       "      <td>11.791231</td>\n",
       "      <td>22.354999</td>\n",
       "      <td>...</td>\n",
       "      <td>56.36628</td>\n",
       "      <td>47.582960</td>\n",
       "      <td>41.421438</td>\n",
       "      <td>44.213180</td>\n",
       "      <td>52.205587</td>\n",
       "      <td>45.824312</td>\n",
       "      <td>31.437935</td>\n",
       "      <td>19.328786</td>\n",
       "      <td>9.496217</td>\n",
       "      <td>2.008118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>241.00000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       pixel1       pixel2       pixel3       pixel4  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      4.480500     0.002500     0.003833     0.029500     0.131000   \n",
       "std       2.885193     0.181198     0.140790     0.514465     3.275865   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       9.000000    14.000000    10.000000    34.000000   146.000000   \n",
       "\n",
       "            pixel5       pixel6       pixel7       pixel8       pixel9  ...  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000  ...   \n",
       "mean      0.234500     0.348667     0.730833     1.840167     5.293500  ...   \n",
       "std       3.793491     5.000393     7.789619    11.791231    22.354999  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max     146.000000   230.000000   189.000000   178.000000   228.000000  ...   \n",
       "\n",
       "         pixel775     pixel776     pixel777     pixel778     pixel779  \\\n",
       "count  6000.00000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean     33.29600    22.255167    16.250167    17.856667    23.363667   \n",
       "std      56.36628    47.582960    41.421438    44.213180    52.205587   \n",
       "min       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%      54.00000     6.000000     0.000000     0.000000     1.000000   \n",
       "max     241.00000   249.000000   239.000000   250.000000   254.000000   \n",
       "\n",
       "          pixel780     pixel781     pixel782     pixel783     pixel784  \n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000  \n",
       "mean     18.388500     9.272833     3.306833     0.878000     0.061667  \n",
       "std      45.824312    31.437935    19.328786     9.496217     2.008118  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max     254.000000   255.000000   248.000000   220.000000    93.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(dataset.select_dtypes(include=[np.number]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.number]).describe())\n",
    "if(dataset.select_dtypes(include=[np.object]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.object]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "label       0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "pixel5      0\n",
      "pixel6      0\n",
      "pixel7      0\n",
      "pixel8      0\n",
      "pixel9      0\n",
      "pixel10     0\n",
      "pixel11     0\n",
      "pixel12     0\n",
      "pixel13     0\n",
      "pixel14     0\n",
      "pixel15     0\n",
      "pixel16     0\n",
      "pixel17     0\n",
      "pixel18     0\n",
      "pixel19     0\n",
      "pixel20     0\n",
      "pixel21     0\n",
      "pixel22     0\n",
      "pixel23     0\n",
      "pixel24     0\n",
      "pixel25     0\n",
      "pixel26     0\n",
      "pixel27     0\n",
      "pixel28     0\n",
      "pixel29     0\n",
      "           ..\n",
      "pixel755    0\n",
      "pixel756    0\n",
      "pixel757    0\n",
      "pixel758    0\n",
      "pixel759    0\n",
      "pixel760    0\n",
      "pixel761    0\n",
      "pixel762    0\n",
      "pixel763    0\n",
      "pixel764    0\n",
      "pixel765    0\n",
      "pixel766    0\n",
      "pixel767    0\n",
      "pixel768    0\n",
      "pixel769    0\n",
      "pixel770    0\n",
      "pixel771    0\n",
      "pixel772    0\n",
      "pixel773    0\n",
      "pixel774    0\n",
      "pixel775    0\n",
      "pixel776    0\n",
      "pixel777    0\n",
      "pixel778    0\n",
      "pixel779    0\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "Length: 785, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for presence of missing values\n",
    "print(\"Missing Values\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualise fields\n",
    "#data_viz(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise fields in relation to target\n",
    "#data_viz_target(dataset, \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate the descriptive features we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = dataset[dataset.columns[1:]]\n",
    "Y = np.array(dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2126 ]  Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4143 ]  T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3680 ]  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAREklEQVR4nO3dbYzV5ZnH8d8lODyKPC0IDLFsxWSRZNEQs8TNxg1aLYnRaroWkwYTIn1RkzbyYtV9UV+q2bbhxabJsJjihrVp0hpNNNsabEL6phF1VtHZlQeH6cDIlCd5Zhi49sX83Yw4/+sez/88Dff3k5CZOdfc59xzzvz4nznXuf+3ubsAXPuua/UEADQHYQcyQdiBTBB2IBOEHcjE5GbemJnx0n8NzCysz5s3r7TW0dERjr3++uvD+pUrV8L6pUuXwvrQ0FBp7fjx4+FY1Mbdx/yFqRR2M7tf0hZJkyT9u7s/X+X6rlWTJk0K65cvXw7rU6dODeuPPPJIaW3x4sXh2M7OzrB++vTpsH7kyJGw3tfXV1rbsWNHOBb1VfPTeDObJOnfJH1b0gpJ681sRb0mBqC+qvzNfqekfe5+wN2HJP1K0oP1mRaAeqsS9iWS/jzq6/7isi8xs01mttvMdle4LQAVVfmbfawXAb7yApy7d0nqkniBDmilKkf2fklLR33dKelwtekAaJQqYX9H0nIzW2ZmHZK+J+n1+kwLQL3V/DTe3YfN7ElJv9NI6+0ld/+objO7hqRaaykvvvhiWH/44YdLax9//HE49sKFC2F9wYIFYf22224L6/fcc09p7Y477gjHbt68Oazj66nUZ3f3NyW9Wae5AGgg3i4LZIKwA5kg7EAmCDuQCcIOZIKwA5lo6nr2a1VqvXnVM/jOmDEjrB84cKC0lloeO3v27LA+ODgY1m+66aawvn///tJaai18VdHjkuNZlTmyA5kg7EAmCDuQCcIOZIKwA5kg7EAmaL3VQdU2zuOPPx7Wr7su/j957969pbWBgYFwbKo1t2/fvrAeLWGV4rPLpk5jvXbt2rC+c+fOsJ5jey3CkR3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUzQZ6+DuXPnhvU1a9aE9aeeeiqsHzx4MKxHS0W7u7vDsTfeeGNYX7Ei3qtz165dYT1aArtu3bpw7MqVK8N6aunv22+/XVo7c+ZMOPZaxJEdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMWDPX/JrZhF1gvGrVqtLaCy+8EI7t6ekJ68PDw2E9darqW265pbT2xhtvhGMXLlwY1lNrzlP1Y8eOldbmzJkTjk1tdZ06DXZnZ2dpbePGjeHYEydOhPV25u5j/sJUelONmfVKOi3psqRhd19d5foANE493kH3j+5+tA7XA6CB+JsdyETVsLuk35vZu2a2aaxvMLNNZrbbzHZXvC0AFVR9Gn+Xux82swWS3jKz/3H3L62McPcuSV3SxH6BDpjoKh3Z3f1w8XFQ0quS7qzHpADUX81hN7MZZnbDF59L+pakPfWaGID6qvI0fqGkV4se8GRJ/+nu/1WXWbWhxx57rLT2/vvvh2OPHz8e1qdNmxbWU+d2j3rCqV710qVLw/pnn30W1nt7e8N61If//PPPw7EpQ0NDYf3kyZOltQceeCAc+/LLL9c0p3ZWc9jd/YCkv63jXAA0EK03IBOEHcgEYQcyQdiBTBB2IBOcSnqcFi1aVFpLbWs8c+bMSrcdLROVpI6OjtJa1H6SpE8++SSsp7aLjk4VLcVbRqeuO3Wq6EmTJoX18+fPl9aWL18ejr0WcWQHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAT9NkL0emYpXipaKrfG22pLKWXsKaWqUZLPbu6usKxzzzzTFhPne750UcfDetnz54trU2ZMiUcu2XLlrCeesxOnTpVWkv9XPPnzw/rR49OvHOscmQHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAT9NkL9957b1iP+qo33HBDODbVZ0/VU9siDw4OltZSa+1T151ac75169awHkm9PyG1nn3WrFlh/dy5c6W1ixcvhmNTPXz67ADaFmEHMkHYgUwQdiAThB3IBGEHMkHYgUzQZy/cfvvtYb2np6e0tmTJknBsqp+c6vmmxkf95G3btoVjU73sCxcuhPUrV66EdXcvraXeX5Baxx+dL1+KzxOQ+rlS752YiJJHdjN7ycwGzWzPqMvmmtlbZra3+BifCQBAy43nafwvJd1/1WVPS9rp7ssl7Sy+BtDGkmF3912Sjl918YOSthefb5f0UJ3nBaDOav2bfaG7D0iSuw+Y2YKybzSzTZI21Xg7AOqk4S/QuXuXpC5JMrPyV2sANFStrbcjZrZIkoqP5cuuALSFWsP+uqQNxecbJL1Wn+kAaJTk03gze0XS3ZLmm1m/pJ9Iel7Sr81so6Q+Sd9t5CSb4dChQw277tSa8Kp99qgnnOpVp3rdqduuYtq0aWH9zJkzla5/+vTpNV/3vHnzKt12O0qG3d3Xl5TW1nkuABqIt8sCmSDsQCYIO5AJwg5kgrADmWCJ6zhFLazFixdXuu7oVNBSekvnaMvmRrfWqixxjWpSuiU5d+7csB49Ln19feFYMwvrExFHdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkGfvZBahhr1k1OnJT5//nxYnzw5fhhSvfJIqo9e5bolaXh4uOaxVd8D0N3dHdbXrFlTWkttVZ06xfZExJEdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFM0GcvpPrFUd/14MGD4dhUH76zszOsHz58OKxH/ejUuuyqp5quItpqWpJmz54d1o8ePRrW+/v7S2upHn4jT6HdKhzZgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBH32Qmo9e0dHR2kt1atOXXe0tbCUPjd7dP2pc7M3+rzx0fsXUuv4U/dblfcARI+nlH5MJ6Lkkd3MXjKzQTPbM+qy58zskJl1F//WNXaaAKoaz9P4X0q6f4zLf+7uq4p/b9Z3WgDqLRl2d98l6XgT5gKggaq8QPekmX1QPM2fU/ZNZrbJzHab2e4KtwWgolrD/gtJ35S0StKApJ+WfaO7d7n7andfXeNtAaiDmsLu7kfc/bK7X5G0VdKd9Z0WgHqrKexmtmjUl9+RtKfsewG0h2Sf3cxekXS3pPlm1i/pJ5LuNrNVklxSr6QfNHCObe/s2bNhfc6c0pc0JKV7vilRvzrVB6+qSj+66pryKmvxUz3+1PsTJqJk2N19/RgXb2vAXAA0EG+XBTJB2IFMEHYgE4QdyARhBzLBEtdClWWkKalTIqdaSKk2ULT9cJUtlaXGLoGtum1yI1tv1yKO7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZCK/ZmOJKn3XVC966tSpYT21pXNq2+WhoaHSWur9A6kefmp8lSWuqbFVl/5GPxtbNgO4ZhF2IBOEHcgEYQcyQdiBTBB2IBOEHcgEffZCar161LNN9Yurns45te67kadzTvX4G9mPTj0mqfcvRBp9iu12xJEdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFM0GcvVNmit2rPNtVPrrLuO7VWvtHruqO5p36uc+fOhfXU3Ko8Lqn3F0xEySO7mS01sz+YWY+ZfWRmPyoun2tmb5nZ3uJjvAk5gJYaz9P4YUmb3f1vJP2dpB+a2QpJT0va6e7LJe0svgbQppJhd/cBd3+v+Py0pB5JSyQ9KGl78W3bJT3UqEkCqO5r/c1uZt+QdLukP0la6O4D0sh/CGa2oGTMJkmbqk0TQFXjDruZzZT0G0k/dvdT430Bw927JHUV11H7q2AAKhlX683MrtdI0He4+2+Li4+Y2aKivkjSYGOmCKAekkd2GzmEb5PU4+4/G1V6XdIGSc8XH19ryAwngKpLUKu2v6psi5x6hpZqSabq0c9etXU2a9assD59+vTS2unTp8OxVbboblfjeRp/l6TvS/rQzLqLy57VSMh/bWYbJfVJ+m5jpgigHpJhd/c/Sir7739tfacDoFGuvecqAMZE2IFMEHYgE4QdyARhBzLBEtdCqt8c9V2nTZsWjk31i1P95pkzZ4b1ixcvltZSP1fqPQDRdtBSelvl6GdL3Xbq5071yoeHh0trqcesyum52xVHdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkGfvZBa9x3VT5w4EY5N9apTWw+fP38+rEdS67JTffLUewSiXrYkTZ5c/it29uzZcOylS5fC+rFjx8L6zTffXFq7FvvoKRzZgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBH32QqofHfXZUz3bVB9+9uzZYT3Vh4/WrKfmluqjR+deH8/46PZnzJgRjk09Jqn7Jbr+U6dOhWNT77uYiDiyA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQifHsz75U0suSbpJ0RVKXu28xs+ckPSHpL8W3PuvubzZqoo2W6ulGPdtPP/00HPvEE0+E9WjNt5TuCUfjU3321Hr01Jry1Dnvp0yZUlpLraVfsGBBWN+/f39Yj84DkNrbPfVzTUTjeVPNsKTN7v6emd0g6V0ze6uo/dzd/7Vx0wNQL+PZn31A0kDx+Wkz65G0pNETA1BfX+tvdjP7hqTbJf2puOhJM/vAzF4yszklYzaZ2W4z211ppgAqGXfYzWympN9I+rG7n5L0C0nflLRKI0f+n441zt273H21u6+uw3wB1GhcYTez6zUS9B3u/ltJcvcj7n7Z3a9I2irpzsZNE0BVybDbyJKqbZJ63P1noy5fNOrbviNpT/2nB6BexvNq/F2Svi/pQzPrLi57VtJ6M1slySX1SvpBQ2bYJCdPngzrK1euLK2ltkVesWJFWD969GhYT81t/vz5pTV3D8dWbTGlWnPREtjU3M6dOxfW+/r6wvqtt95aWlu8eHE4dmBgIKxPRON5Nf6Pksb6bZ6wPXUgR7yDDsgEYQcyQdiBTBB2IBOEHcgEYQcywamkC/39/WG9t7e3tJZaorps2bJapoSK7rvvvprHph7TiYgjO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmbDUmuK63pjZXyQdHHXRfEnxYu7Wade5teu8JOZWq3rO7WZ3/6uxCk0N+1du3Gx3u56brl3n1q7zkphbrZo1N57GA5kg7EAmWh32rhbffqRd59au85KYW62aMreW/s0OoHlafWQH0CSEHchES8JuZveb2f+a2T4ze7oVcyhjZr1m9qGZdbd6f7piD71BM9sz6rK5ZvaWme0tPo65x16L5vacmR0q7rtuM1vXorktNbM/mFmPmX1kZj8qLm/pfRfMqyn3W9P/ZjezSZI+kXSvpH5J70ha7+4fN3UiJcysV9Jqd2/5GzDM7B8knZH0sruvLC57UdJxd3+++I9yjrv/c5vM7TlJZ1q9jXexW9Gi0duMS3pI0uNq4X0XzOuf1IT7rRVH9jsl7XP3A+4+JOlXkh5swTzanrvvknT8qosflLS9+Hy7Rn5Zmq5kbm3B3Qfc/b3i89OSvthmvKX3XTCvpmhF2JdI+vOor/vVXvu9u6Tfm9m7Zrap1ZMZw0J3H5BGfnkkLWjxfK6W3Ma7ma7aZrxt7rtatj+vqhVhH2srqXbq/93l7ndI+rakHxZPVzE+49rGu1nG2Ga8LdS6/XlVrQh7v6Slo77ulHS4BfMYk7sfLj4OSnpV7bcV9ZEvdtAtPg62eD7/r5228R5rm3G1wX3Xyu3PWxH2dyQtN7NlZtYh6XuSXm/BPL7CzGYUL5zIzGZI+pbabyvq1yVtKD7fIOm1Fs7lS9plG++ybcbV4vuu5dufu3vT/0lap5FX5PdL+pdWzKFkXn8t6b+Lfx+1em6SXtHI07pLGnlGtFHSPEk7Je0tPs5to7n9h6QPJX2gkWAtatHc/l4jfxp+IKm7+Leu1fddMK+m3G+8XRbIBO+gAzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE/8HcoqXSa7zFlQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4249 ]  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4793 ]  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5842 ]  Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3117 ]  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3311 ]  T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3500 ]  Sneaker\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a sample of images from the dataset\n",
    "for i in range(0, 9):\n",
    "    i_rand = randint(0, X.shape[0])\n",
    "\n",
    "    print(\"[\", i_rand, \"] \", classes[Y[i_rand]])\n",
    "    two_d = (X.iloc[i_rand].values.reshape(28, 28))\n",
    "    pyplot.imshow(two_d, cmap='gray')\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the data (important for some models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract some higher level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_filled</th>\n",
       "      <th>percent_filled_top</th>\n",
       "      <th>percent_filled_bottom</th>\n",
       "      <th>row_sum_0</th>\n",
       "      <th>row_sum_1</th>\n",
       "      <th>row_sum_2</th>\n",
       "      <th>row_sum_3</th>\n",
       "      <th>row_sum_4</th>\n",
       "      <th>row_sum_5</th>\n",
       "      <th>row_sum_6</th>\n",
       "      <th>...</th>\n",
       "      <th>row_sum_19</th>\n",
       "      <th>row_sum_20</th>\n",
       "      <th>row_sum_21</th>\n",
       "      <th>row_sum_22</th>\n",
       "      <th>row_sum_23</th>\n",
       "      <th>row_sum_24</th>\n",
       "      <th>row_sum_25</th>\n",
       "      <th>row_sum_26</th>\n",
       "      <th>row_sum_27</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53309</th>\n",
       "      <td>0.345208</td>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.472669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243277</td>\n",
       "      <td>0.373249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820308</td>\n",
       "      <td>0.843838</td>\n",
       "      <td>0.828711</td>\n",
       "      <td>0.147619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48366</th>\n",
       "      <td>0.290416</td>\n",
       "      <td>0.277621</td>\n",
       "      <td>0.303211</td>\n",
       "      <td>0.099020</td>\n",
       "      <td>0.177451</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.251681</td>\n",
       "      <td>0.263725</td>\n",
       "      <td>0.286975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372409</td>\n",
       "      <td>0.350280</td>\n",
       "      <td>0.297759</td>\n",
       "      <td>0.242437</td>\n",
       "      <td>0.237955</td>\n",
       "      <td>0.240616</td>\n",
       "      <td>0.236415</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.122689</td>\n",
       "      <td>0.170918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23101</th>\n",
       "      <td>0.354047</td>\n",
       "      <td>0.240686</td>\n",
       "      <td>0.467407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782913</td>\n",
       "      <td>0.755182</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.511204</td>\n",
       "      <td>0.058263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td>0.361815</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.487355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028291</td>\n",
       "      <td>0.236835</td>\n",
       "      <td>0.387955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810364</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.769188</td>\n",
       "      <td>0.774230</td>\n",
       "      <td>0.452241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38653</th>\n",
       "      <td>0.163856</td>\n",
       "      <td>0.192947</td>\n",
       "      <td>0.134764</td>\n",
       "      <td>0.113165</td>\n",
       "      <td>0.217787</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.226751</td>\n",
       "      <td>0.198739</td>\n",
       "      <td>0.214006</td>\n",
       "      <td>0.235574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134874</td>\n",
       "      <td>0.153922</td>\n",
       "      <td>0.162465</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.147339</td>\n",
       "      <td>0.149720</td>\n",
       "      <td>0.144118</td>\n",
       "      <td>0.143417</td>\n",
       "      <td>0.088095</td>\n",
       "      <td>0.043367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49741</th>\n",
       "      <td>0.441787</td>\n",
       "      <td>0.456923</td>\n",
       "      <td>0.426651</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.170588</td>\n",
       "      <td>0.446359</td>\n",
       "      <td>0.474790</td>\n",
       "      <td>0.498880</td>\n",
       "      <td>0.512185</td>\n",
       "      <td>0.510644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546639</td>\n",
       "      <td>0.548039</td>\n",
       "      <td>0.543697</td>\n",
       "      <td>0.541036</td>\n",
       "      <td>0.538655</td>\n",
       "      <td>0.190056</td>\n",
       "      <td>0.165546</td>\n",
       "      <td>0.131513</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11769</th>\n",
       "      <td>0.372229</td>\n",
       "      <td>0.321128</td>\n",
       "      <td>0.423329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746359</td>\n",
       "      <td>0.787955</td>\n",
       "      <td>0.746499</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>0.152731</td>\n",
       "      <td>0.150720</td>\n",
       "      <td>0.154742</td>\n",
       "      <td>0.045378</td>\n",
       "      <td>0.081092</td>\n",
       "      <td>0.087255</td>\n",
       "      <td>0.110084</td>\n",
       "      <td>0.126751</td>\n",
       "      <td>0.128431</td>\n",
       "      <td>0.158683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189076</td>\n",
       "      <td>0.179412</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.146078</td>\n",
       "      <td>0.135294</td>\n",
       "      <td>0.125070</td>\n",
       "      <td>0.124650</td>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.010224</td>\n",
       "      <td>0.082908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>0.402006</td>\n",
       "      <td>0.453511</td>\n",
       "      <td>0.350500</td>\n",
       "      <td>0.206022</td>\n",
       "      <td>0.488655</td>\n",
       "      <td>0.505462</td>\n",
       "      <td>0.515406</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.561625</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351120</td>\n",
       "      <td>0.364846</td>\n",
       "      <td>0.363585</td>\n",
       "      <td>0.375490</td>\n",
       "      <td>0.386555</td>\n",
       "      <td>0.431232</td>\n",
       "      <td>0.335014</td>\n",
       "      <td>0.415826</td>\n",
       "      <td>0.145378</td>\n",
       "      <td>0.225765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53625</th>\n",
       "      <td>0.337925</td>\n",
       "      <td>0.333103</td>\n",
       "      <td>0.342747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202101</td>\n",
       "      <td>0.358123</td>\n",
       "      <td>0.324650</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.337675</td>\n",
       "      <td>0.349160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610784</td>\n",
       "      <td>0.596499</td>\n",
       "      <td>0.582073</td>\n",
       "      <td>0.366807</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>0.020168</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       percent_filled  percent_filled_top  percent_filled_bottom  row_sum_0  \\\n",
       "53309        0.345208            0.217747               0.472669   0.000000   \n",
       "48366        0.290416            0.277621               0.303211   0.099020   \n",
       "23101        0.354047            0.240686               0.467407   0.000000   \n",
       "9417         0.361815            0.236275               0.487355   0.000000   \n",
       "38653        0.163856            0.192947               0.134764   0.113165   \n",
       "49741        0.441787            0.456923               0.426651   0.000280   \n",
       "11769        0.372229            0.321128               0.423329   0.000000   \n",
       "3624         0.152731            0.150720               0.154742   0.045378   \n",
       "8365         0.402006            0.453511               0.350500   0.206022   \n",
       "53625        0.337925            0.333103               0.342747   0.000000   \n",
       "\n",
       "       row_sum_1  row_sum_2  row_sum_3  row_sum_4  row_sum_5  row_sum_6  ...  \\\n",
       "53309   0.000000   0.000000   0.000000   0.000000   0.243277   0.373249  ...   \n",
       "48366   0.177451   0.211765   0.238095   0.251681   0.263725   0.286975  ...   \n",
       "23101   0.000000   0.000000   0.000000   0.000000   0.002801   0.152941  ...   \n",
       "9417    0.000000   0.000000   0.000000   0.028291   0.236835   0.387955  ...   \n",
       "38653   0.217787   0.200700   0.226751   0.198739   0.214006   0.235574  ...   \n",
       "49741   0.170588   0.446359   0.474790   0.498880   0.512185   0.510644  ...   \n",
       "11769   0.000000   0.000000   0.000000   0.000000   0.000000   0.233473  ...   \n",
       "3624    0.081092   0.087255   0.110084   0.126751   0.128431   0.158683  ...   \n",
       "8365    0.488655   0.505462   0.515406   0.514706   0.561625   0.561905  ...   \n",
       "53625   0.202101   0.358123   0.324650   0.337255   0.337675   0.349160  ...   \n",
       "\n",
       "       row_sum_19  row_sum_20  row_sum_21  row_sum_22  row_sum_23  row_sum_24  \\\n",
       "53309    0.820308    0.843838    0.828711    0.147619    0.000000    0.000000   \n",
       "48366    0.372409    0.350280    0.297759    0.242437    0.237955    0.240616   \n",
       "23101    0.782913    0.755182    0.780392    0.511204    0.058263    0.000000   \n",
       "9417     0.810364    0.813025    0.769188    0.774230    0.452241    0.000000   \n",
       "38653    0.134874    0.153922    0.162465    0.152941    0.147339    0.149720   \n",
       "49741    0.546639    0.548039    0.543697    0.541036    0.538655    0.190056   \n",
       "11769    0.746359    0.787955    0.746499    0.019608    0.000000    0.000000   \n",
       "3624     0.189076    0.179412    0.161905    0.146078    0.135294    0.125070   \n",
       "8365     0.351120    0.364846    0.363585    0.375490    0.386555    0.431232   \n",
       "53625    0.610784    0.596499    0.582073    0.366807    0.030952    0.020868   \n",
       "\n",
       "       row_sum_25  row_sum_26  row_sum_27  symmetry  \n",
       "53309    0.000000    0.000000    0.000000  0.093112  \n",
       "48366    0.236415    0.261905    0.122689  0.170918  \n",
       "23101    0.000000    0.000000    0.000000  0.110969  \n",
       "9417     0.000000    0.000000    0.000000  0.102041  \n",
       "38653    0.144118    0.143417    0.088095  0.043367  \n",
       "49741    0.165546    0.131513    0.000140  0.204082  \n",
       "11769    0.000000    0.000000    0.000000  0.150510  \n",
       "3624     0.124650    0.055462    0.010224  0.082908  \n",
       "8365     0.335014    0.415826    0.145378  0.225765  \n",
       "53625    0.020168    0.016667    0.000000  0.099490  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engineered_features = pd.DataFrame()\n",
    "\n",
    "# Calcualte percentage of filled pixels and a top and bottom half only version\n",
    "percent_filled = X.sum(axis = 1)/(28*28)\n",
    "percent_filled_top = X.iloc[:, 0:392].sum(axis = 1)/(28*14)\n",
    "percent_filled_bottom = X.iloc[:, 392:784].sum(axis = 1)/(28*14)\n",
    "engineered_features['percent_filled'] = percent_filled\n",
    "engineered_features['percent_filled_top'] = percent_filled_top\n",
    "engineered_features['percent_filled_bottom'] = percent_filled_bottom\n",
    "\n",
    "# Calculate the sum of each row\n",
    "for idx, i in enumerate(range(0, 784, 28)):\n",
    "    row_sum = X.iloc[:, i:(i + 28)].sum(axis = 1)/28\n",
    "    engineered_features[\"row_sum_\" + str(idx)] = row_sum\n",
    "\n",
    "# Calcualte a measure of syymmetry around a horizontal axis\n",
    "s1 = np.round(np.array(X.iloc[:, 0:392]))\n",
    "s2 = np.round(np.array(X.iloc[:, 784:391:-1]))\n",
    "s3 = np.logical_and(s1, s2).astype(int)\n",
    "symmetry = s3.sum(axis = 1)/(28*28)\n",
    "\n",
    "engineered_features['symmetry'] = symmetry\n",
    "\n",
    "display(engineered_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = engineered_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a **training set**, a **vaidation set**, and a **test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test \\\n",
    "    = train_test_split(X, Y, random_state=0, \\\n",
    "                                    train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid \\\n",
    "    = train_test_split(X_train_plus_valid, \\\n",
    "                                        y_train_plus_valid, \\\n",
    "                                        random_state=0, \\\n",
    "                                        train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Very Simple Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       323\n",
      "           1       1.00      1.00      1.00       306\n",
      "           2       1.00      1.00      1.00       277\n",
      "           3       1.00      1.00      1.00       286\n",
      "           4       1.00      1.00      1.00       302\n",
      "           5       1.00      1.00      1.00       298\n",
      "           6       1.00      1.00      1.00       274\n",
      "           7       1.00      1.00      1.00       303\n",
      "           8       1.00      1.00      1.00       322\n",
      "           9       1.00      1.00      1.00       309\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>323</td>\n",
       "      <td>306</td>\n",
       "      <td>277</td>\n",
       "      <td>286</td>\n",
       "      <td>302</td>\n",
       "      <td>298</td>\n",
       "      <td>274</td>\n",
       "      <td>303</td>\n",
       "      <td>322</td>\n",
       "      <td>309</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          323    0    0    0    0    0    0    0    0    0   323\n",
       "1            0  306    0    0    0    0    0    0    0    0   306\n",
       "2            0    0  277    0    0    0    0    0    0    0   277\n",
       "3            0    0    0  286    0    0    0    0    0    0   286\n",
       "4            0    0    0    0  302    0    0    0    0    0   302\n",
       "5            0    0    0    0    0  298    0    0    0    0   298\n",
       "6            0    0    0    0    0    0  274    0    0    0   274\n",
       "7            0    0    0    0    0    0    0  303    0    0   303\n",
       "8            0    0    0    0    0    0    0    0  322    0   322\n",
       "9            0    0    0    0    0    0    0    0    0  309   309\n",
       "All        323  306  277  286  302  298  274  303  322  309  3000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_train, y_pred))\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58       111\n",
      "           1       0.79      0.88      0.83       122\n",
      "           2       0.46      0.42      0.44       125\n",
      "           3       0.59      0.53      0.56       132\n",
      "           4       0.46      0.42      0.44       124\n",
      "           5       0.76      0.66      0.70       132\n",
      "           6       0.29      0.31      0.30       112\n",
      "           7       0.72      0.77      0.75       110\n",
      "           8       0.76      0.82      0.79        97\n",
      "           9       0.74      0.77      0.76       135\n",
      "\n",
      "    accuracy                           0.62      1200\n",
      "   macro avg       0.61      0.62      0.62      1200\n",
      "weighted avg       0.61      0.62      0.61      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>104</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>119</td>\n",
       "      <td>136</td>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>105</td>\n",
       "      <td>140</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           67    2    3   16    4    0   18    0    1    0   111\n",
       "1            4  107    1    4    3    1    2    0    0    0   122\n",
       "2            8    3   53    5   28    0   19    0    4    5   125\n",
       "3           17   17    7   70    2    1   18    0    0    0   132\n",
       "4            1    2   29    9   52    0   24    0    4    3   124\n",
       "5            0    1    2    2    2   87    0   22    3   13   132\n",
       "6           21    4   15    9   21    0   35    0    3    4   112\n",
       "7            0    0    1    0    0   13    0   85    3    8   110\n",
       "8            0    0    3    2    1    4    1    3   80    3    97\n",
       "9            1    0    2    1    1    9    2    8    7  104   135\n",
       "All        119  136  116  118  114  115  119  118  105  140  1200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6266666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58       166\n",
      "           1       0.77      0.85      0.81       198\n",
      "           2       0.56      0.48      0.52       198\n",
      "           3       0.59      0.54      0.57       174\n",
      "           4       0.54      0.57      0.55       188\n",
      "           5       0.74      0.67      0.70       184\n",
      "           6       0.31      0.32      0.31       172\n",
      "           7       0.67      0.72      0.69       169\n",
      "           8       0.78      0.74      0.76       174\n",
      "           9       0.73      0.76      0.74       177\n",
      "\n",
      "    accuracy                           0.63      1800\n",
      "   macro avg       0.63      0.63      0.62      1800\n",
      "weighted avg       0.63      0.63      0.63      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "      <td>10</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>134</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>174</td>\n",
       "      <td>220</td>\n",
       "      <td>171</td>\n",
       "      <td>158</td>\n",
       "      <td>199</td>\n",
       "      <td>167</td>\n",
       "      <td>180</td>\n",
       "      <td>183</td>\n",
       "      <td>165</td>\n",
       "      <td>183</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           99   12    9   15   10    0   19    0    2    0   166\n",
       "1            7  169    4   10    1    0    7    0    0    0   198\n",
       "2            6    0   96    7   36    1   42    0    2    8   198\n",
       "3           22   24    3   94    6    4   18    0    2    1   174\n",
       "4            3    5   28   11  107    1   28    0    3    2   188\n",
       "5            1    1    1    1    1  123    1   41    6    8   184\n",
       "6           30    3   21   19   32    2   55    0    6    4   172\n",
       "7            0    0    0    0    0   26    0  122    5   16   169\n",
       "8            6    3    7    1    4    4    5    5  129   10   174\n",
       "9            0    3    2    0    2    6    5   15   10  134   177\n",
       "All        174  220  171  158  199  167  180  183  165  183  1800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less Overiftted Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree, setting min samples per leaf to a sensible value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split = 200)\n",
    "my_tree = my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6093333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.61      0.53       323\n",
      "           1       0.88      0.67      0.76       306\n",
      "           2       0.44      0.31      0.37       277\n",
      "           3       0.52      0.51      0.51       286\n",
      "           4       0.45      0.64      0.53       302\n",
      "           5       0.80      0.68      0.74       298\n",
      "           6       0.30      0.16      0.21       274\n",
      "           7       0.80      0.80      0.80       303\n",
      "           8       0.74      0.82      0.78       322\n",
      "           9       0.66      0.78      0.72       309\n",
      "\n",
      "    accuracy                           0.61      3000\n",
      "   macro avg       0.61      0.60      0.59      3000\n",
      "weighted avg       0.61      0.61      0.60      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>205</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>147</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>26</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>242</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>419</td>\n",
       "      <td>233</td>\n",
       "      <td>199</td>\n",
       "      <td>285</td>\n",
       "      <td>431</td>\n",
       "      <td>254</td>\n",
       "      <td>148</td>\n",
       "      <td>305</td>\n",
       "      <td>360</td>\n",
       "      <td>366</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          196   11   41   25   15    2   17    0   12    4   323\n",
       "1            9  205   20   64    2    1    2    0    0    3   306\n",
       "2           32    2   87    5   94    0   33    0   10   14   277\n",
       "3           70   11   10  147   34    0    6    0    5    3   286\n",
       "4           29    2    3   18  194    1   40    0    7    8   302\n",
       "5            6    0    0    4    0  204    1   51    9   23   298\n",
       "6           66    2   31   17   83    2   45    0   17   11   274\n",
       "7            0    0    0    0    0   18    0  243   10   32   303\n",
       "8            7    0    6    1    6    5    4    2  265   26   322\n",
       "9            4    0    1    4    3   21    0    9   25  242   309\n",
       "All        419  233  199  285  431  254  148  305  360  366  3000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.61      0.52       111\n",
      "           1       0.87      0.65      0.74       122\n",
      "           2       0.35      0.21      0.26       125\n",
      "           3       0.50      0.50      0.50       132\n",
      "           4       0.44      0.69      0.53       124\n",
      "           5       0.72      0.61      0.66       132\n",
      "           6       0.29      0.16      0.21       112\n",
      "           7       0.72      0.72      0.72       110\n",
      "           8       0.71      0.84      0.77        97\n",
      "           9       0.64      0.76      0.69       135\n",
      "\n",
      "    accuracy                           0.57      1200\n",
      "   macro avg       0.57      0.57      0.56      1200\n",
      "weighted avg       0.57      0.57      0.56      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>10</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>102</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>151</td>\n",
       "      <td>91</td>\n",
       "      <td>75</td>\n",
       "      <td>132</td>\n",
       "      <td>194</td>\n",
       "      <td>111</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>114</td>\n",
       "      <td>160</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1   2    3    4    5   6    7    8    9   All\n",
       "True                                                          \n",
       "0           68   2  15    7    6    0  11    0    2    0   111\n",
       "1            6  79   5   28    1    2   1    0    0    0   122\n",
       "2           18   1  26    6   49    0  17    0    2    6   125\n",
       "3           29   8   8   66   12    1   5    0    3    0   132\n",
       "4            3   1   9   11   85    1   9    0    2    3   124\n",
       "5            2   0   0    0    0   80   0   28    3   19   132\n",
       "6           21   0  12   12   39    1  18    0    5    4   112\n",
       "7            0   0   0    0    0   10   0   79    5   16   110\n",
       "8            1   0   0    1    0    2   1    1   81   10    97\n",
       "9            3   0   0    1    2   14   0    2   11  102   135\n",
       "All        151  91  75  132  194  111  62  110  114  160  1200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5644444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.55      0.47       166\n",
      "           1       0.81      0.66      0.73       198\n",
      "           2       0.41      0.24      0.30       198\n",
      "           3       0.44      0.51      0.47       174\n",
      "           4       0.46      0.65      0.54       188\n",
      "           5       0.80      0.62      0.70       184\n",
      "           6       0.21      0.10      0.14       172\n",
      "           7       0.68      0.73      0.70       169\n",
      "           8       0.70      0.78      0.74       174\n",
      "           9       0.62      0.81      0.70       177\n",
      "\n",
      "    accuracy                           0.56      1800\n",
      "   macro avg       0.55      0.57      0.55      1800\n",
      "weighted avg       0.56      0.56      0.55      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>130</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>16</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>144</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>224</td>\n",
       "      <td>160</td>\n",
       "      <td>115</td>\n",
       "      <td>198</td>\n",
       "      <td>266</td>\n",
       "      <td>144</td>\n",
       "      <td>84</td>\n",
       "      <td>183</td>\n",
       "      <td>193</td>\n",
       "      <td>233</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           92    7   25   19    7    0   9    0    5    2   166\n",
       "1            6  130   16   41    2    1   1    0    0    1   198\n",
       "2           18    1   47    9   74    0  30    0    7   12   198\n",
       "3           39   16    2   88   15    2   8    0    2    2   174\n",
       "4           12    4    2   16  122    1  16    0    8    7   188\n",
       "5            5    0    0    0    0  115   0   45    5   14   184\n",
       "6           50    1   19   20   40    4  18    0   11    9   172\n",
       "7            0    0    0    0    0   12   0  124    7   26   169\n",
       "8            2    0    4    2    5    2   2    5  136   16   174\n",
       "9            0    1    0    3    1    7   0    9   12  144   177\n",
       "All        224  160  115  198  266  144  84  183  193  233  1800"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Parameters Using a Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a cross validation to perfrom an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62971698 0.60377358 0.64539007 0.63270142 0.63333333 0.63571429\n",
      " 0.60287081 0.66985646 0.64423077 0.60481928]\n"
     ]
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(max_depth = 12)\n",
    "scores = cross_val_score(my_tree, X_train_plus_valid, y_train_plus_valid, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to using post pruning explicitly is to use a grid search through a large set of possible parameters. Here we try depths between 3 and 20 and different limits on the minimum number of samples per split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.1s\n",
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5702380952380952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02891934, 0.03342974, 0.03187525, 0.03789544, 0.03191292,\n",
       "        0.03743017, 0.03174007, 0.0354048 , 0.03590167, 0.03141451,\n",
       "        0.0334096 , 0.03191614, 0.0319134 , 0.03490591, 0.03390884,\n",
       "        0.03141475, 0.07280469, 0.11020517, 0.10872757, 0.10172772,\n",
       "        0.10820866, 0.1027441 , 0.15009964, 0.12067616, 0.09479463,\n",
       "        0.12114823, 0.15907466, 0.12117481, 0.0977726 , 0.10121036,\n",
       "        0.09426522, 0.09973276]),\n",
       " 'std_fit_time': array([1.99782848e-03, 2.47323513e-03, 4.04119492e-05, 3.99088860e-03,\n",
       "        1.07288361e-06, 5.51712513e-03, 8.23855400e-04, 4.99367714e-04,\n",
       "        1.99496746e-03, 4.98294830e-04, 2.49361992e-03, 9.99689102e-04,\n",
       "        9.96947289e-04, 2.99143791e-03, 1.99460983e-03, 4.98533249e-04,\n",
       "        5.98311424e-03, 2.49004364e-03, 1.97899342e-03, 1.00493431e-03,\n",
       "        3.49617004e-03, 2.97236443e-03, 2.24372149e-02, 2.19403505e-02,\n",
       "        2.94411182e-03, 8.46564770e-03, 1.84515715e-02, 2.04463005e-02,\n",
       "        2.99000740e-03, 3.47304344e-03, 2.51269341e-03, 7.94255733e-03]),\n",
       " 'mean_score_time': array([0.00149727, 0.00149524, 0.00150144, 0.00249481, 0.00199604,\n",
       "        0.00147891, 0.00099862, 0.00149941, 0.00149703, 0.00150132,\n",
       "        0.00149703, 0.00199676, 0.00152242, 0.00199556, 0.00149632,\n",
       "        0.00199592, 0.00099826, 0.00198138, 0.00150168, 0.00199163,\n",
       "        0.00199699, 0.00201631, 0.00348961, 0.00149775, 0.00101566,\n",
       "        0.00398827, 0.00299323, 0.00149846, 0.00199413, 0.00199807,\n",
       "        0.00200939, 0.00147855]),\n",
       " 'std_score_time': array([4.99486923e-04, 5.01036644e-04, 5.02705574e-04, 4.99486923e-04,\n",
       "        0.00000000e+00, 5.17129898e-04, 3.57627869e-07, 4.97579575e-04,\n",
       "        4.98771667e-04, 4.94241714e-04, 4.98533249e-04, 2.38418579e-07,\n",
       "        5.24640083e-04, 4.76837158e-07, 4.98771667e-04, 1.19209290e-07,\n",
       "        4.76837158e-07, 1.58548355e-05, 4.94122505e-04, 5.12599945e-06,\n",
       "        2.38418579e-07, 2.12192535e-05, 1.49428844e-03, 4.98294830e-04,\n",
       "        1.83582306e-05, 1.99747086e-03, 9.96470451e-04, 4.99725342e-04,\n",
       "        3.33786011e-06, 1.78813934e-06, 1.62124634e-05, 4.80532646e-04]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42,\n",
       "                    45, 48, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36,\n",
       "                    39, 42, 45, 48],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 48, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 48, 'min_samples_split': 200}],\n",
       " 'split0_test_score': array([0.49024274, 0.5801999 , 0.5801999 , 0.5801999 , 0.5801999 ,\n",
       "        0.5801999 , 0.5801999 , 0.5801999 , 0.5801999 , 0.5801999 ,\n",
       "        0.5801999 , 0.5801999 , 0.5801999 , 0.5801999 , 0.5801999 ,\n",
       "        0.5801999 , 0.49357449, 0.57686816, 0.57686816, 0.57686816,\n",
       "        0.57686816, 0.57686816, 0.57686816, 0.57686816, 0.57686816,\n",
       "        0.57686816, 0.57686816, 0.57686816, 0.57686816, 0.57686816,\n",
       "        0.57686816, 0.57686816]),\n",
       " 'split1_test_score': array([0.47641734, 0.56026679, 0.56026679, 0.56026679, 0.56026679,\n",
       "        0.56026679, 0.56026679, 0.56026679, 0.56026679, 0.56026679,\n",
       "        0.56026679, 0.56026679, 0.56026679, 0.56026679, 0.56026679,\n",
       "        0.56026679, 0.48404002, 0.52405908, 0.52977608, 0.52977608,\n",
       "        0.52977608, 0.52977608, 0.52977608, 0.52977608, 0.52977608,\n",
       "        0.52977608, 0.52977608, 0.52977608, 0.52977608, 0.52977608,\n",
       "        0.52977608, 0.52977608]),\n",
       " 'mean_test_score': array([0.48333333, 0.5702381 , 0.5702381 , 0.5702381 , 0.5702381 ,\n",
       "        0.5702381 , 0.5702381 , 0.5702381 , 0.5702381 , 0.5702381 ,\n",
       "        0.5702381 , 0.5702381 , 0.5702381 , 0.5702381 , 0.5702381 ,\n",
       "        0.5702381 , 0.48880952, 0.55047619, 0.55333333, 0.55333333,\n",
       "        0.55333333, 0.55333333, 0.55333333, 0.55333333, 0.55333333,\n",
       "        0.55333333, 0.55333333, 0.55333333, 0.55333333, 0.55333333,\n",
       "        0.55333333, 0.55333333]),\n",
       " 'std_test_score': array([0.0069127 , 0.00996655, 0.00996655, 0.00996655, 0.00996655,\n",
       "        0.00996655, 0.00996655, 0.00996655, 0.00996655, 0.00996655,\n",
       "        0.00996655, 0.00996655, 0.00996655, 0.00996655, 0.00996655,\n",
       "        0.00996655, 0.00476723, 0.02640454, 0.02354603, 0.02354603,\n",
       "        0.02354603, 0.02354603, 0.02354603, 0.02354603, 0.02354603,\n",
       "        0.02354603, 0.02354603, 0.02354603, 0.02354603, 0.02354603,\n",
       "        0.02354603, 0.02354603]),\n",
       " 'rank_test_score': array([32,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 31,\n",
       "        30, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " 'split0_train_score': array([0.49595045, 0.60314435, 0.60314435, 0.60314435, 0.60314435,\n",
       "        0.60314435, 0.60314435, 0.60314435, 0.60314435, 0.60314435,\n",
       "        0.60314435, 0.60314435, 0.60314435, 0.60314435, 0.60314435,\n",
       "        0.60314435, 0.49499762, 0.61696046, 0.61696046, 0.61696046,\n",
       "        0.61696046, 0.61696046, 0.61696046, 0.61696046, 0.61696046,\n",
       "        0.61696046, 0.61696046, 0.61696046, 0.61696046, 0.61696046,\n",
       "        0.61696046, 0.61696046]),\n",
       " 'split1_train_score': array([0.50975726, 0.61827701, 0.61827701, 0.61827701, 0.61827701,\n",
       "        0.61827701, 0.61827701, 0.61827701, 0.61827701, 0.61827701,\n",
       "        0.61827701, 0.61827701, 0.61827701, 0.61827701, 0.61827701,\n",
       "        0.61827701, 0.52022846, 0.57401238, 0.58305569, 0.58305569,\n",
       "        0.58305569, 0.58305569, 0.58305569, 0.58305569, 0.58305569,\n",
       "        0.58305569, 0.58305569, 0.58305569, 0.58305569, 0.58305569,\n",
       "        0.58305569, 0.58305569]),\n",
       " 'mean_train_score': array([0.50285386, 0.61071068, 0.61071068, 0.61071068, 0.61071068,\n",
       "        0.61071068, 0.61071068, 0.61071068, 0.61071068, 0.61071068,\n",
       "        0.61071068, 0.61071068, 0.61071068, 0.61071068, 0.61071068,\n",
       "        0.61071068, 0.50761304, 0.59548642, 0.60000807, 0.60000807,\n",
       "        0.60000807, 0.60000807, 0.60000807, 0.60000807, 0.60000807,\n",
       "        0.60000807, 0.60000807, 0.60000807, 0.60000807, 0.60000807,\n",
       "        0.60000807, 0.60000807]),\n",
       " 'std_train_score': array([0.0069034 , 0.00756633, 0.00756633, 0.00756633, 0.00756633,\n",
       "        0.00756633, 0.00756633, 0.00756633, 0.00756633, 0.00756633,\n",
       "        0.00756633, 0.00756633, 0.00756633, 0.00756633, 0.00756633,\n",
       "        0.00756633, 0.01261542, 0.02147404, 0.01695238, 0.01695238,\n",
       "        0.01695238, 0.01695238, 0.01695238, 0.01695238, 0.01695238,\n",
       "        0.01695238, 0.01695238, 0.01695238, 0.01695238, 0.01695238,\n",
       "        0.01695238, 0.01695238])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid ={'criterion': ['gini', \"entropy\"], \\\n",
    "             'max_depth': list(range(3, 50, 3)), \\\n",
    "             'min_samples_split': [200]}\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_tree = GridSearchCV(tree.DecisionTreeClassifier(), \\\n",
    "                                param_grid, cv=cv_folds, verbose = 2, \\\n",
    "                            return_train_score=True)\n",
    "my_tuned_tree.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_tree.best_params_)\n",
    "model_tuned_params_list[\"Tuned Tree\"] = my_tuned_tree.best_params_\n",
    "display(my_tuned_tree.best_score_)\n",
    "display(my_tuned_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5694444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.32      0.43       166\n",
      "           1       0.75      0.74      0.74       198\n",
      "           2       0.51      0.38      0.44       198\n",
      "           3       0.40      0.45      0.42       174\n",
      "           4       0.46      0.40      0.43       188\n",
      "           5       0.82      0.61      0.70       184\n",
      "           6       0.27      0.48      0.34       172\n",
      "           7       0.61      0.79      0.69       169\n",
      "           8       0.80      0.77      0.79       174\n",
      "           9       0.73      0.75      0.74       177\n",
      "\n",
      "    accuracy                           0.57      1800\n",
      "   macro avg       0.60      0.57      0.57      1800\n",
      "weighted avg       0.60      0.57      0.57      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>81</td>\n",
       "      <td>195</td>\n",
       "      <td>148</td>\n",
       "      <td>199</td>\n",
       "      <td>164</td>\n",
       "      <td>138</td>\n",
       "      <td>306</td>\n",
       "      <td>219</td>\n",
       "      <td>167</td>\n",
       "      <td>183</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                            \n",
       "0          53    5   10   32   14    0   48    0    2    2   166\n",
       "1           1  146   14   17    1    1   17    0    0    1   198\n",
       "2           2    6   76   20   39    0   52    0    2    1   198\n",
       "3          12   22    3   79    6    2   46    0    3    1   174\n",
       "4           1   12   22   21   75    0   49    0    7    1   188\n",
       "5           0    0    0    0    0  113    5   50    4   12   184\n",
       "6          12    3   17   27   20    3   82    0    5    3   172\n",
       "7           0    0    0    0    0   13    0  134    5   17   169\n",
       "8           0    0    5    1    2    2    3   15  134   12   174\n",
       "9           0    1    1    2    7    4    4   20    5  133   177\n",
       "All        81  195  148  199  164  138  306  219  167  183  1800"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily use the same patterns to train other types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=200,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.RandomForestClassifier(n_estimators=300, \\\n",
    "                                           max_features = 3,\\\n",
    "                                           min_samples_split=200)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65       111\n",
      "           1       0.64      0.90      0.75       122\n",
      "           2       0.47      0.36      0.41       125\n",
      "           3       0.45      0.63      0.52       132\n",
      "           4       0.48      0.60      0.53       124\n",
      "           5       0.74      0.66      0.70       132\n",
      "           6       0.50      0.02      0.03       112\n",
      "           7       0.72      0.81      0.76       110\n",
      "           8       0.82      0.85      0.83        97\n",
      "           9       0.77      0.79      0.78       135\n",
      "\n",
      "    accuracy                           0.62      1200\n",
      "   macro avg       0.62      0.63      0.60      1200\n",
      "weighted avg       0.62      0.62      0.60      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>112</td>\n",
       "      <td>171</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "      <td>155</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>138</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2    3    4    5  6    7    8    9   All\n",
       "True                                                          \n",
       "0           72   15   3   17    1    1  0    0    2    0   111\n",
       "1            3  110   1    7    0    0  0    0    1    0   122\n",
       "2            6   11  45   27   35    0  0    0    0    1   125\n",
       "3           12   22   5   83    5    2  0    0    2    1   132\n",
       "4            1    6  25   12   74    1  2    0    2    1   124\n",
       "5            0    0   0    3    1   87  0   25    3   13   132\n",
       "6           17    6  15   28   37    1  2    0    4    2   112\n",
       "7            0    0   0    0    0   13  0   89    0    8   110\n",
       "8            0    0   0    3    0    3  0    3   82    6    97\n",
       "9            1    1   1    5    2    9  0    6    4  106   135\n",
       "All        112  171  95  185  155  117  4  123  100  138  1200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.9s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.9s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   0.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   0.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   1.0s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   1.0s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   1.2s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   1.2s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.6s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.7s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   1.0s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   1.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   1.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.8s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   2.3s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   2.8s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.8s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   0.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   1.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   1.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   1.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.8s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   2.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   2.1s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   2.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   2.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   2.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   2.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   1.1s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   1.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   1.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   1.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   1.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   1.8s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   1.8s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   2.1s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   2.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   2.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   2.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   2.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   2.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   2.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 8, 'min_samples_split': 200, 'n_estimators': 100}\n",
      "0.6023809523809524\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(100, 501, 50)), 'max_features': list(range(2, 10, 2)), 'min_samples_split': [200] }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Random Forest\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6566666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       166\n",
      "           1       0.80      0.89      0.84       198\n",
      "           2       0.59      0.55      0.57       198\n",
      "           3       0.44      0.68      0.53       174\n",
      "           4       0.56      0.64      0.60       188\n",
      "           5       0.76      0.71      0.73       184\n",
      "           6       0.39      0.12      0.19       172\n",
      "           7       0.73      0.73      0.73       169\n",
      "           8       0.88      0.82      0.85       174\n",
      "           9       0.75      0.80      0.78       177\n",
      "\n",
      "    accuracy                           0.66      1800\n",
      "   macro avg       0.65      0.65      0.64      1800\n",
      "weighted avg       0.65      0.66      0.64      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>14</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>142</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>165</td>\n",
       "      <td>222</td>\n",
       "      <td>184</td>\n",
       "      <td>268</td>\n",
       "      <td>214</td>\n",
       "      <td>172</td>\n",
       "      <td>54</td>\n",
       "      <td>170</td>\n",
       "      <td>162</td>\n",
       "      <td>189</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           99    9   14   32    5    0   4    0    2    1   166\n",
       "1            3  177    2   14    1    1   0    0    0    0   198\n",
       "2           13    3  109   15   42    0  15    0    0    1   198\n",
       "3           19   23    5  118    4    1   2    0    1    1   174\n",
       "4            2    4   25   23  120    0  10    0    4    0   188\n",
       "5            0    0    1    7    0  130   0   33    2   11   184\n",
       "6           28    6   20   51   38    4  21    0    2    2   172\n",
       "7            0    0    0    0    0   25   0  124    3   17   169\n",
       "8            1    0    6    3    1    3   0    4  142   14   174\n",
       "9            0    0    2    5    3    8   2    9    6  142   177\n",
       "All        165  222  184  268  214  172  54  170  162  189  1800"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='entropy',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=50,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=10, n_jobs=None,\n",
       "                  oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.BaggingClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 50), \\\n",
    "                                      n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6133333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.62      0.57       111\n",
      "           1       0.73      0.89      0.80       122\n",
      "           2       0.41      0.34      0.38       125\n",
      "           3       0.56      0.58      0.57       132\n",
      "           4       0.47      0.66      0.55       124\n",
      "           5       0.70      0.67      0.68       132\n",
      "           6       0.35      0.12      0.18       112\n",
      "           7       0.69      0.71      0.70       110\n",
      "           8       0.84      0.77      0.81        97\n",
      "           9       0.73      0.76      0.75       135\n",
      "\n",
      "    accuracy                           0.61      1200\n",
      "   macro avg       0.60      0.61      0.60      1200\n",
      "weighted avg       0.60      0.61      0.60      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>76</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>130</td>\n",
       "      <td>148</td>\n",
       "      <td>104</td>\n",
       "      <td>136</td>\n",
       "      <td>173</td>\n",
       "      <td>126</td>\n",
       "      <td>40</td>\n",
       "      <td>113</td>\n",
       "      <td>89</td>\n",
       "      <td>141</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7   8    9   All\n",
       "True                                                           \n",
       "0           69    7    9   14    1    0  10    0   1    0   111\n",
       "1            5  108    1    6    0    2   0    0   0    0   122\n",
       "2           12   12   43    8   41    0   8    0   0    1   125\n",
       "3           20   15   10   76    7    1   1    0   2    0   132\n",
       "4            3    1   20   12   82    1   3    0   1    1   124\n",
       "5            0    0    0    3    1   88   1   25   2   12   132\n",
       "6           20    4   18   10   40    0  14    0   3    3   112\n",
       "7            0    0    0    0    0   19   0   78   2   11   110\n",
       "8            0    0    0    4    0    2   2    4  75   10    97\n",
       "9            1    1    3    3    1   13   1    6   3  103   135\n",
       "All        130  148  104  136  173  126  40  113  89  141  1200"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50, total=   1.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50, total=   1.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100, total=   3.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100, total=   7.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150, total=  17.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150, total=   7.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200, total=   9.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200, total=  10.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250, total=  11.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250, total=  12.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300, total=  15.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300, total=  15.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350, total=  17.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350, total=  17.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400, total=  19.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400, total=  19.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450, total=  27.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450, total=  23.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500, total=  25.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500, total=  23.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 400}\n",
      "0.4092857142857143\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    "  'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.BaggingClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Bagging\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5844444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.52      0.51       166\n",
      "           1       0.61      0.88      0.72       198\n",
      "           2       0.55      0.46      0.50       198\n",
      "           3       0.37      0.51      0.43       174\n",
      "           4       0.52      0.51      0.51       188\n",
      "           5       0.78      0.67      0.72       184\n",
      "           6       0.30      0.10      0.15       172\n",
      "           7       0.70      0.74      0.72       169\n",
      "           8       0.70      0.74      0.72       174\n",
      "           9       0.70      0.69      0.69       177\n",
      "\n",
      "    accuracy                           0.58      1800\n",
      "   macro avg       0.57      0.58      0.57      1800\n",
      "weighted avg       0.57      0.58      0.57      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>91</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>122</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>173</td>\n",
       "      <td>287</td>\n",
       "      <td>164</td>\n",
       "      <td>235</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>61</td>\n",
       "      <td>179</td>\n",
       "      <td>184</td>\n",
       "      <td>175</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           86   17   17   27    5    0   9    0    3    2   166\n",
       "1            6  175    3   10    1    1   1    0    0    1   198\n",
       "2           19   23   91   20   37    0   4    0    3    1   198\n",
       "3           22   32    5   88    4    2  18    0    2    1   174\n",
       "4            6   25   21   18   95    1  10    0   12    0   188\n",
       "5            1    0    0    8    0  124   0   40    0   11   184\n",
       "6           29   15   21   47   32    3  18    0    5    2   172\n",
       "7            0    0    0    0    0   17   0  125    7   20   169\n",
       "8            2    0    5   13    3    3   1    4  128   15   174\n",
       "9            2    0    1    4    6    8   0   10   24  122   177\n",
       "All        173  287  164  235  183  159  61  179  184  175  1800"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='entropy',\n",
       "                                                         max_depth=None,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=200,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1.0, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.AdaBoostClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 200), \\\n",
    "                                       n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4608333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.39      0.43       111\n",
      "           1       0.75      0.76      0.76       122\n",
      "           2       0.26      0.31      0.28       125\n",
      "           3       0.38      0.30      0.33       132\n",
      "           4       0.38      0.41      0.40       124\n",
      "           5       0.54      0.39      0.45       132\n",
      "           6       0.28      0.25      0.26       112\n",
      "           7       0.41      0.58      0.48       110\n",
      "           8       0.48      0.58      0.52        97\n",
      "           9       0.70      0.66      0.68       135\n",
      "\n",
      "    accuracy                           0.46      1200\n",
      "   macro avg       0.46      0.46      0.46      1200\n",
      "weighted avg       0.47      0.46      0.46      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>89</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>90</td>\n",
       "      <td>124</td>\n",
       "      <td>151</td>\n",
       "      <td>102</td>\n",
       "      <td>134</td>\n",
       "      <td>95</td>\n",
       "      <td>101</td>\n",
       "      <td>158</td>\n",
       "      <td>117</td>\n",
       "      <td>128</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4   5    6    7    8    9   All\n",
       "True                                                           \n",
       "0          43    3   31   14    2   0   16    0    2    0   111\n",
       "1           2   93    3   10    8   0    6    0    0    0   122\n",
       "2          10    2   39   11   39   2   14    1    3    4   125\n",
       "3          14   23   18   39   11   4   21    0    1    1   132\n",
       "4           5    2   32    5   51   1   14    0   10    4   124\n",
       "5           0    0    1    4    0  51    2   54    7   13   132\n",
       "6          14    1   23   13   21   1   28    0    6    5   112\n",
       "7           0    0    1    0    0  27    0   64   16    2   110\n",
       "8           1    0    1    2    1   7    0   19   56   10    97\n",
       "9           1    0    2    4    1   2    0   20   16   89   135\n",
       "All        90  124  151  102  134  95  101  158  117  128  1200"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50, total=   5.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50, total=   5.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100, total=  10.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100, total=  10.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150, total=  16.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150, total=  15.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200, total=  22.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200, total=  21.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250, total=  26.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250, total=  27.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300, total=  33.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300, total=  32.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350, total=  37.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350, total=  36.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400, total=  43.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400, total=  43.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450, total=  50.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450, total=  60.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500, total= 1.0min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500, total= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 10.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 300}\n",
      "0.5914285714285714\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    " 'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.AdaBoostClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned AdaBoost\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       166\n",
      "           1       0.89      0.83      0.86       198\n",
      "           2       0.51      0.57      0.53       198\n",
      "           3       0.58      0.64      0.61       174\n",
      "           4       0.48      0.47      0.48       188\n",
      "           5       0.73      0.43      0.54       184\n",
      "           6       0.33      0.35      0.34       172\n",
      "           7       0.52      0.85      0.65       169\n",
      "           8       0.85      0.80      0.83       174\n",
      "           9       0.82      0.64      0.72       177\n",
      "\n",
      "    accuracy                           0.61      1800\n",
      "   macro avg       0.63      0.61      0.61      1800\n",
      "weighted avg       0.64      0.61      0.62      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>165</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>111</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>140</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>151</td>\n",
       "      <td>185</td>\n",
       "      <td>221</td>\n",
       "      <td>190</td>\n",
       "      <td>184</td>\n",
       "      <td>110</td>\n",
       "      <td>182</td>\n",
       "      <td>275</td>\n",
       "      <td>164</td>\n",
       "      <td>138</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           93    4   11   24    5    0   27    0    1    1   166\n",
       "1           10  165    3   13    2    1    4    0    0    0   198\n",
       "2            4    0  112    2   42    0   35    0    1    2   198\n",
       "3           24   15    7  111    7    0   10    0    0    0   174\n",
       "4            1    0   51    7   89    0   37    0    3    0   188\n",
       "5            0    0    0    5    0   80    2   86    3    8   184\n",
       "6           16    0   32   27   35    0   60    0    2    0   172\n",
       "7            0    0    0    0    0   18    0  144    4    3   169\n",
       "8            3    0    3    1    3    4    2    7  140   11   174\n",
       "9            0    1    2    0    1    7    5   38   10  113   177\n",
       "All        151  185  221  190  184  110  182  275  164  138  1800"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with logistic regression\n",
    "my_model = linear_model.LogisticRegression()\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6208333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63       111\n",
      "           1       0.62      0.89      0.73       122\n",
      "           2       0.53      0.50      0.51       125\n",
      "           3       0.54      0.51      0.52       132\n",
      "           4       0.56      0.53      0.55       124\n",
      "           5       0.71      0.64      0.67       132\n",
      "           6       0.33      0.14      0.20       112\n",
      "           7       0.71      0.80      0.75       110\n",
      "           8       0.69      0.84      0.76        97\n",
      "           9       0.76      0.72      0.74       135\n",
      "\n",
      "    accuracy                           0.62      1200\n",
      "   macro avg       0.60      0.62      0.61      1200\n",
      "weighted avg       0.60      0.62      0.61      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>97</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>128</td>\n",
       "      <td>174</td>\n",
       "      <td>120</td>\n",
       "      <td>124</td>\n",
       "      <td>117</td>\n",
       "      <td>119</td>\n",
       "      <td>49</td>\n",
       "      <td>124</td>\n",
       "      <td>117</td>\n",
       "      <td>128</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           75   17    1   13    0    2   1    0    2    0   111\n",
       "1            9  108    2    3    0    0   0    0    0    0   122\n",
       "2            1   16   63    8   18    2  11    0    4    2   125\n",
       "3           20   20   10   67    2    6   4    0    2    1   132\n",
       "4            1    7   20    7   66    2   8    0   13    0   124\n",
       "5            1    0    0    5    1   84   3   24    1   13   132\n",
       "6           21    5   17   14   28    4  16    0    4    3   112\n",
       "7            0    0    0    0    0   14   0   88    1    7   110\n",
       "8            0    0    0    4    1    2   1    3   81    5    97\n",
       "9            0    1    7    3    1    3   5    9    9   97   135\n",
       "All        128  174  120  124  117  119  49  124  117  128  1200"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.2s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.2s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.2s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.2s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.2s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.2s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.2s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.3s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.3s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.3s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.3s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.3s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.3s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.3s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.2s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.4s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.3s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1.6, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
      "0.6080952380952381\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'multi_class': ['ovr'], \n",
    " 'C': [x / 10.0 for x in range(2, 21, 2)],\n",
    " 'solver':['liblinear'],\n",
    "  'max_iter':[1000]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(linear_model.LogisticRegression(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Logistic Regression\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6283333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.62       166\n",
      "           1       0.70      0.90      0.79       198\n",
      "           2       0.56      0.54      0.55       198\n",
      "           3       0.50      0.60      0.54       174\n",
      "           4       0.50      0.51      0.51       188\n",
      "           5       0.67      0.66      0.66       184\n",
      "           6       0.40      0.18      0.25       172\n",
      "           7       0.71      0.83      0.76       169\n",
      "           8       0.71      0.71      0.71       174\n",
      "           9       0.76      0.75      0.75       177\n",
      "\n",
      "    accuracy                           0.63      1800\n",
      "   macro avg       0.62      0.63      0.61      1800\n",
      "weighted avg       0.62      0.63      0.62      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>106</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>17</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>132</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>151</td>\n",
       "      <td>253</td>\n",
       "      <td>189</td>\n",
       "      <td>212</td>\n",
       "      <td>191</td>\n",
       "      <td>181</td>\n",
       "      <td>78</td>\n",
       "      <td>198</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           99   23   10   18    5    1   3    0    7    0   166\n",
       "1            4  178    2   10    2    1   1    0    0    0   198\n",
       "2            6   11  106   13   40    4  15    0    3    0   198\n",
       "3           17   23    5  105    6   11   2    0    5    0   174\n",
       "4            5    7   33    8   96    4  18    0   16    1   188\n",
       "5            0    0    1    8    0  121   0   41    1   12   184\n",
       "6           18   11   21   41   33    9  31    0    7    1   172\n",
       "7            0    0    0    0    0   17   0  140    1   11   169\n",
       "8            2    0    4    8    7    6   1    6  123   17   174\n",
       "9            0    0    7    1    2    7   7   11   10  132   177\n",
       "All        151  253  189  212  191  181  78  198  173  174  1800"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neighbors.KNeighborsClassifier()\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6858333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70       111\n",
      "           1       0.68      0.96      0.79       122\n",
      "           2       0.54      0.53      0.53       125\n",
      "           3       0.63      0.58      0.61       132\n",
      "           4       0.53      0.58      0.55       124\n",
      "           5       0.85      0.67      0.75       132\n",
      "           6       0.43      0.31      0.36       112\n",
      "           7       0.78      0.88      0.83       110\n",
      "           8       0.92      0.86      0.89        97\n",
      "           9       0.84      0.79      0.82       135\n",
      "\n",
      "    accuracy                           0.69      1200\n",
      "   macro avg       0.69      0.69      0.68      1200\n",
      "weighted avg       0.69      0.69      0.68      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>116</td>\n",
       "      <td>173</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>137</td>\n",
       "      <td>105</td>\n",
       "      <td>82</td>\n",
       "      <td>125</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7   8    9   All\n",
       "True                                                           \n",
       "0           80   10    0   12    1    0   7    0   1    0   111\n",
       "1            2  117    0    1    0    0   2    0   0    0   122\n",
       "2            1    3   66    6   28    1  18    0   1    1   125\n",
       "3            9   24    5   77    6    0  10    0   0    1   132\n",
       "4            1    7   27    6   72    0   9    0   1    1   124\n",
       "5            0    1    3    7    4   89   0   20   1    7   132\n",
       "6           22    8   21    5   18    0  35    0   1    2   112\n",
       "7            0    0    0    0    0    7   0   97   0    6   110\n",
       "8            0    0    0    5    2    2   1    2  83    2    97\n",
       "9            1    3    1    3    6    6   0    6   2  107   135\n",
       "All        116  173  123  122  137  105  82  125  90  127  1200"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... n_neighbors=1, total=   0.4s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... n_neighbors=1, total=   0.3s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.4s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.6s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   0.5s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   0.5s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   0.5s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   0.4s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   0.6s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   0.6s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   0.6s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   0.5s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   0.6s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   0.6s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   0.6s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   0.5s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   0.5s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   0.5s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   0.5s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   0.5s\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 6}\n",
      "0.6597619047619048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   10.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'n_neighbors': list(range(1, 50, 5))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neighbors.KNeighborsClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned kNN\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6983333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68       166\n",
      "           1       0.75      0.95      0.84       198\n",
      "           2       0.62      0.65      0.63       198\n",
      "           3       0.52      0.64      0.57       174\n",
      "           4       0.57      0.60      0.58       188\n",
      "           5       0.86      0.72      0.78       184\n",
      "           6       0.49      0.38      0.43       172\n",
      "           7       0.79      0.80      0.80       169\n",
      "           8       0.93      0.76      0.84       174\n",
      "           9       0.78      0.80      0.79       177\n",
      "\n",
      "    accuracy                           0.70      1800\n",
      "   macro avg       0.70      0.70      0.70      1800\n",
      "weighted avg       0.70      0.70      0.70      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>111</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>9</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>147</td>\n",
       "      <td>251</td>\n",
       "      <td>209</td>\n",
       "      <td>213</td>\n",
       "      <td>195</td>\n",
       "      <td>155</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "      <td>143</td>\n",
       "      <td>180</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          107   15    5   23    2    0   12    0    2    0   166\n",
       "1            0  189    1    4    2    0    2    0    0    0   198\n",
       "2            5    5  129    8   29    0   19    0    0    3   198\n",
       "3           11   29    6  111    7    0    9    0    1    0   174\n",
       "4            2    1   33   18  112    0   20    0    2    0   188\n",
       "5            0    1    1   14    2  133    0   23    2    8   184\n",
       "6           22   10   21   25   27    0   66    0    1    0   172\n",
       "7            0    0    0    0    0   14    0  136    0   19   169\n",
       "8            0    1    9    4    7    6    3    2  133    9   174\n",
       "9            0    0    4    6    7    2    3   12    2  141   177\n",
       "All        147  251  209  213  195  155  134  173  143  180  1800"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neural_network.MLPClassifier(hidden_layer_sizes=(300, 100))\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7308333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       111\n",
      "           1       0.90      0.92      0.91       122\n",
      "           2       0.63      0.66      0.64       125\n",
      "           3       0.67      0.72      0.70       132\n",
      "           4       0.72      0.47      0.57       124\n",
      "           5       0.82      0.71      0.76       132\n",
      "           6       0.44      0.50      0.47       112\n",
      "           7       0.77      0.87      0.82       110\n",
      "           8       0.84      0.89      0.86        97\n",
      "           9       0.83      0.84      0.84       135\n",
      "\n",
      "    accuracy                           0.73      1200\n",
      "   macro avg       0.73      0.73      0.73      1200\n",
      "weighted avg       0.74      0.73      0.73      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>114</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>118</td>\n",
       "      <td>125</td>\n",
       "      <td>130</td>\n",
       "      <td>141</td>\n",
       "      <td>81</td>\n",
       "      <td>114</td>\n",
       "      <td>128</td>\n",
       "      <td>124</td>\n",
       "      <td>102</td>\n",
       "      <td>137</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3   4    5    6    7    8    9   All\n",
       "True                                                            \n",
       "0           84    2    2   12   0    0    9    0    2    0   111\n",
       "1            1  112    0    5   2    0    2    0    0    0   122\n",
       "2            1    0   82    7  12    0   20    0    1    2   125\n",
       "3            9   10    4   95   1    1   10    0    1    1   132\n",
       "4            2    1   24   10  58    1   25    0    3    0   124\n",
       "5            2    0    0    1   0   94    2   19    5    9   132\n",
       "6           17    0   17    9   8    0   56    0    1    4   112\n",
       "7            1    0    0    0   0    8    0   96    0    5   110\n",
       "8            1    0    0    1   0    3    3    1   86    2    97\n",
       "9            0    0    1    1   0    7    1    8    3  114   135\n",
       "All        118  125  130  141  81  114  128  124  102  137  1200"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=  13.2s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=  11.3s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  27.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  29.2s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  22.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  31.2s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  10.3s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  11.0s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  28.0s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  28.2s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  33.3s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  33.1s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=  11.0s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=  11.0s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=  28.4s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=  28.6s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=  33.7s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=  33.5s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=  11.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=  10.9s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=  28.2s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=  28.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=  33.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=  33.3s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=  12.5s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=  12.7s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=  33.2s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=  32.9s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=  39.5s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=  36.2s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   7.4s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   7.4s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=  21.3s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=  20.3s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=  19.4s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=  19.0s\n",
      "Best parameters set found on development set:\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (400, 200, 100)}\n",
      "0.7340476190476191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neural_network.MLPClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned MLP\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       166\n",
      "           1       0.85      0.93      0.89       198\n",
      "           2       0.76      0.55      0.64       198\n",
      "           3       0.61      0.78      0.69       174\n",
      "           4       0.60      0.73      0.66       188\n",
      "           5       0.80      0.82      0.81       184\n",
      "           6       0.50      0.35      0.42       172\n",
      "           7       0.77      0.83      0.80       169\n",
      "           8       0.88      0.86      0.87       174\n",
      "           9       0.87      0.77      0.81       177\n",
      "\n",
      "    accuracy                           0.73      1800\n",
      "   macro avg       0.73      0.73      0.73      1800\n",
      "weighted avg       0.74      0.73      0.73      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>136</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>171</td>\n",
       "      <td>217</td>\n",
       "      <td>144</td>\n",
       "      <td>220</td>\n",
       "      <td>227</td>\n",
       "      <td>189</td>\n",
       "      <td>121</td>\n",
       "      <td>183</td>\n",
       "      <td>171</td>\n",
       "      <td>157</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          119    8    2   22    3    1    7    0    3    1   166\n",
       "1            2  184    1    8    0    1    2    0    0    0   198\n",
       "2            6    2  109    8   45    0   22    0    1    5   198\n",
       "3           13   15    0  135    6    1    4    0    0    0   174\n",
       "4            4    1   10   12  137    1   21    0    2    0   188\n",
       "5            0    0    0    2    0  151    0   23    6    2   184\n",
       "6           23    6   15   31   32    1   61    0    2    1   172\n",
       "7            1    0    0    0    0   18    0  141    1    8   169\n",
       "8            3    1    6    1    2    3    2    2  150    4   174\n",
       "9            0    0    1    1    2   12    2   17    6  136   177\n",
       "All        171  217  144  220  227  189  121  183  171  157  1800"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Simple Tree': 0.6266666666666667,\n",
       " 'Better Tree': 0.5644444444444444,\n",
       " 'Tuned Tree': 0.5694444444444444,\n",
       " 'Tuned Random Forest': 0.6566666666666666,\n",
       " 'Tuned Bagging': 0.5844444444444444,\n",
       " 'Tuned AdaBoost': 0.615,\n",
       " 'Tuned Logistic Regression': 0.6283333333333333,\n",
       " 'Tuned kNN': 0.6983333333333334,\n",
       " 'Tuned MLP': 0.735}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_test_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.values()), align='center')\n",
    "_ = plt.yticks(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Simple Tree': 0.6166666666666667,\n",
       " 'Better Tree': 0.57,\n",
       " 'Random Forest': 0.625,\n",
       " 'Bagging': 0.6133333333333333,\n",
       " 'AdaBoost': 0.4608333333333333,\n",
       " 'Logistic Regression': 0.6208333333333333,\n",
       " 'kNN': 0.6858333333333333,\n",
       " 'MLP': 0.7308333333333333}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_valid_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAD4CAYAAABhR9aJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAcKklEQVR4nO3de5ydVX3v8c/XILeCQQVtGi3TargISJSQgkUEqehRC1LxCEoFteWoVVtbaWPrUWqx0IOeIkXFaBHQIhxrVRQV1HLxAsgEcgEPeBTQgj0HUIjcxfA7f+wVszvNZJ6ZzMyeST7v1yuvPHs961nPb1YSvqy1n9mTqkKSJG3YYwZdgCRJs4GBKUlSBwamJEkdGJiSJHVgYEqS1MEWgy5AE7fjjjvW0NDQoMuQpFll2bJld1XVTuO9zsCcxYaGhhgeHh50GZI0qyT54USuc0tWkqQODExJkjowMCVJ6sDAlCSpAwNTkqQODExJkjowMCVJ6sDAlCSpAz+4YBZbdftqhpZcNOgyJE2SW095yaBL0Aa4wpQkqQMDU5KkDgxMSZI6MDAlSerAwJQkqQMDU5KkDgzMKZCkknyi7/UWSe5M8sX2+rgkZ6znuluTrEqyIsklSX51OuuWJI3OwJwa9wN7JtmmvX4BcHvHaw+uqr2BYeAvp6I4SdL4GZhT58vA2u9CPhr41DivvwJ4+qRWJEmaMANz6pwPHJVka+CZwNXjvP6lwKqRjUmOTzKcZHjNA6snoUxJUhcG5hSpqpXAEL3V5ZfGcemlSZYDjwNOXs+4S6tqUVUtmrPt3EmpVZI0Nj9LdmpdCLwPOAh4YsdrDq6qu6asIknShBiYU+ssYHVVrUpy0KCLkSRNnFuyU6iqbquqD4xy+rgkt/X9esq0FidJGhdXmFOgqrZbT9tlwGXt+Gzg7PVcOjR1VUmSNoYrTEmSOjAwJUnqwMCUJKkDA1OSpA4MTEmSOvAp2Vlsr/lzGT7lJWN3lCRtNFeYkiR1YGBKktSBgSlJUgcGpiRJHfjQzyy26vbVDC25aNBlSOpzqw/ibbJcYUqS1IGBKUlSBwamJEkdGJiSJHVgYEqS1IGBKUlSBwbmJEsylOT6EW0HJakkv9vX9sUkB7Xjy5IM951blOSy6apZkjQ2A3P63Ab81QbOPynJf5muYiRJ42NgTqEkv5nkOmBfYAWwOskLRul+KvDOaStOkjQuBuYUSbIr8BngtcA1rfkkRg/FK4GHkxw8xrjHJxlOMrzmgdWTVq8kacMMzKmxE/B54JiqWr62saq+AZDkuaNct6FAXTvG0qpaVFWL5mw7d7LqlSSNwcCcGquBfwN+ez3n3sso72VW1b8CWwP7TV1pkqSJMDCnxs+BlwGvSfKq/hNVdQnweGDvUa59L/DnU1ueJGm8DMwpUlX3Ay8F3gaM3Dt9L/CUUa77EnDn1FYnSRovf7zXJKuqW4E92/E99J6Qhd57mmv7XAik7/VBI8bYZ6rrlCSNjytMSZI6MDAlSerAwJQkqQMDU5KkDnzoZxbba/5chk95yaDLkKTNgitMSZI6MDAlSerAwJQkqQMDU5KkDnzoZxZbdftqhpZcNOgypFnpVh+Y0zi5wpQkqQMDU5KkDgxMSZI6MDAlSerAwJQkqQMDU5KkDsYMzCT3bexNkvxakn/ewPkdkrypa//1XH92kluSLE+yIskhG1vzZEryhiSvGXQdkqSJm5YVZlX9uKqO3ECXHYA3jaP/+pxQVQuBPwHOnECZ/0mSSfk+1ao6s6rOnYyxJEmDMaHATLJzkq8nWdl+//XW/rQkVyW5Jsl71q5Okwwlub4d75HkO201uDLJAuAU4Gmt7dQR/eckeV+SVa3/W8Yo70pgfl+t+yS5PMmyJBcnmdfa923jXdnuufZ+xyX5dJIvAJe0thPa17QyyV+3tl9JclFb0V6f5JWt/ZQk321939faTkzy9na8sM3RyiSfTfL41n5Zkr9rc/O9JM+dyJ+NJGlqTHSFeQZwblU9E/gn4PTW/gHgA1W1L/DjUa59Q+uzEFgE3AYsAX5QVQur6oQR/Y8HfgN4Vt/9NuRFwOcAkjwW+AfgyKraBzgLeG/r93HgDVW1P7BmxBj7A8dW1fOTHAosABYDC4F9khzY7vPjqtq7qvYEvpLkCcARwB6t1pPWU9+5wF+086uAd/ed26KqFtNbJb97PdeS5Pgkw0mG1zyweoypkCRNlokG5v7Aee34E8ABfe2fbsfnjbyouRL4yyR/AexcVQ+Oca/fAc6sql8AVNVPR+l3apKbgU8Cf9vadgX2BL6aZDnwTuApSXYAtq+qb49S61f77nNo+3UdcC2wG70AXQX8TlsVPreqVgM/Ax4CPpbk94AH+gdNMhfYoaoub03nAAf2dfmX9vsyYGh9X2RVLa2qRVW1aM62c0eZCknSZJus9zCrc8eq84DDgAeBi5M8f4xL0nH8E4Cn0wvFc/quvaGtXBdW1V5VdWhr35D7R9z/5L4xnl5V/1hV3wP2oRecJyd5Vwv1xcBngJcBX+lQd7+H2+9r8HN+JWlGmWhgfhs4qh2/GvhmO74KeHk7PmrkRQBJfhO4uapOBy4EngncC2w/yr0uAd6w9gGctu25XlX1KL1t4cckeSFwE7BTkv3btY9NskdV3Q3cm2S/DdXaXAy8Lsl2bYz5SZ6U5NeAB6rqk8D7gGe3PnOr6kv0tlUXjqhvNXB33/uTvw9cjiRpxuuyitk2yW19r/8n8FbgrCQnAHcCr23n/gT4ZJI/Ay4C1vcm2yuBY5I8Avxf4D1V9dMk32oP3nwZ+GBf/48BuwAr2zUfpfce6npVVSU5Cfjzqro4yZHA6W07dAvgNOAG4PXAR5PcD1w2Sq1U1SVJdgeuTAJwH3AMvdXsqUkeBR4B3kgv9D+fZGt6K9O3rWfIY4Ezk2wL3Nw3d5KkGSxVnXdTxx6sFwIPttA6Cji6qg6ftBtMoiTbVdXap3iXAPOq6o8HXNa4bDVvQc079rRBlyHNSv54r81XkmVVtWi81032+2T7AGektxS7B3jdJI8/mV6S5B305uCHwHGDLUeSNJNNamBW1TeAvSdzzKlSVRcAFwy6DknS7OBnyUqS1IGBKUlSB36v3yy21/y5DPvggiRNC1eYkiR1YGBKktSBgSlJUgcGpiRJHfjQzyy26vbVDC25aNBlaBPnJ+JIPa4wJUnqwMCUJKkDA1OSpA4MTEmSOjAwJUnqwMCUJKmDzSowkxyRpJLsNsr5s5McOcYYZye5JcnyJDcmefck1/iyJM+YzDElSRtvswpM4Gjgm8BRGznOCVW1EFgIHJvkNza6snVeBhiYkjTDbDaBmWQ74LeB19MCMz1nJPlukouAJ/X1f1eSa5Jcn2Rpkqxn2K3b7/e3aw5Jcl2SVUnOSrLVGO2ntHuvTPK+JM8BDgNObSvYp03VfEiSxmezCUx6K7evVNX3gJ8meTZwBLArsBfwh8Bz+vqfUVX7VtWewDbAS/vOnZpkOXAbcH5V3ZFka+Bs4JVVtRe9T1F64wban9Duv0dVPRM4qaq+DVxIW8FW1Q9GfhFJjk8ynGR4zQOrJ2tuJElj2JwC82jg/HZ8fnt9IPCpqlpTVT8G/rWv/8FJrk6yCng+sEffubVbsr8KHNJWhrsCt7RABjinjT9a+8+Ah4CPJfk94IEuX0RVLa2qRVW1aM62c8fz9UuSNsJm8VmySZ5IL/T2TFLAHKCAz7bfR/bfGvgQsKiq/i3Jiazbfv2lqrovyWXAAcAlo91+fY1V9Yski4FD6G0Rv7nVKEmagTaXFeaRwLlVtXNVDVXVU4FbgJ8CRyWZk2QecHDrvzYc72rvfa73ydkkWwC/BfwAuBEYSvL0dvr3gctHa2/jzq2qLwF/Qu8BIoB7ge0n5auWJE2azSUwj6a3muz3GXpbqv8HWAV8mF7AUVX3AB9t7Z8Drhlx7dr3MFe2Pv9SVQ8BrwU+3bZxHwXOHK2dXih+McnKdt+3tbHPB05oDwn50I8kzRCp+k87kpoltpq3oOYde9qgy9Amzh/vpU1NkmVVtWi8120uK0xJkjaKgSlJUgcGpiRJHRiYkiR1YGBKktTBZvHBBZuqvebPZdgnGCVpWrjClCSpAwNTkqQODExJkjowMCVJ6sCHfmaxVbevZmjJRYMuQ5o1/Jg/bQxXmJIkdWBgSpLUgYEpSVIHBqYkSR0YmJIkdWBgSpLUwWYfmEnWJFmeZEWSa5M8ZwrusSjJ6ZM9riRp+vh9mPBgVS0ESPJC4GTgeZN5g6oaBoYnc0xJ0vTa7FeYIzwOuBsgyXZJvt5WnauSHL62U5L/nuTGJF9N8qkkb2/t+yZZmeTKJKcmub61H5Tki+34xCRnJbksyc1J3jrWuJKkwXOFCdskWQ5sDcwDnt/aHwKOqKqfJdkRuCrJhcA+wMuBZ9Gbv2uBZe2ajwPHV9W3k5yygXvuBhwMbA/clOTDwN4bGPeXkhwPHA8w53E7TfiLliSNjyvMtiVbVbsBLwLOTRIgwN8mWQl8DZgPPBk4APh8VT1YVfcCXwBIsgOwfVV9u4173gbueVFVPVxVdwF3bGjckapqaVUtqqpFc7adu7FfuySpI1eYfarqyraa3Al4cft9n6p6JMmt9FahGeXy0drX5+G+4zX0/hzGc70kaZq5wuyTZDdgDvATYC5wRwvLg4GdW7dvAr+bZOsk2wEvAaiqu4F7k+zX+h01ztuvd1xJ0szgCnPde5jQW+UdW1VrkvwT8IUkw8By4EaAqrqmvZe5AvghvadfV7frXw98NMn9wGV97WMaY1xJ0oClqgZdw6yTZLuqui/JtsAV9B70uXZte+uzBJhXVX+8seOO1n+reQtq3rGnbeRXI20+/PFeAkiyrKoWjfc6V5gTszTJM+i9p3lOX6i9JMk76M3rD4HjJmlcSdKAGZgTUFWvGqX9AuCCyR5XkjR4PvQjSVIHBqYkSR24JTuL7TV/LsM+xCBJ08IVpiRJHRiYkiR1YGBKktSBgSlJUgc+9DOLrbp9NUNLLhp0GdKs5Sf/aDxcYUqS1IGBKUlSBwamJEkdGJiSJHVgYEqS1IGBKUlSBwMJzCRrkixPcn2SLyTZYZLGHUpy/WSMNWLcE5Pc3mpenuSUyb5H370WJnnxVI0vSZqYQa0wH6yqhVW1J/BT4I8GVMd4/H2reWFVLel6UZI547zPQsDAlKQZZiZsyV4JzAdIsl2Srye5NsmqJIe39qEk/zvJR5PckOSSJNu0c/skWZHkSvqCN8nWST7exrkuycGt/bgkn2sr21uSvDnJn7Y+VyV5QtfCkxzSrluV5KwkW7X2W5O8K8k3gVckeVqSryRZluQbSXZr/V7RVtkrklyRZEvgPcAr20r2lZMyw5KkjTbQwGyrr0OAC1vTQ8ARVfVs4GDg/UnSzi0APlhVewD3AC9v7R8H3lpV+48Y/o8Aqmov4GjgnCRbt3N7Aq8CFgPvBR6oqmfRC+/XjFLu2/q2ZF/YxjobeGW7xxbAG/v6P1RVB1TV+cBS4C1VtQ/wduBDrc+7gBdW1d7AYVX189Z2QVvJXrCeOTs+yXCS4TUPrB6lVEnSZBtUYG6TZDnwE+AJwFdbe4C/TbIS+Bq9leeT27lbqmp5O14GDCWZC+xQVZe39k/03eOAta+r6kbgh8Au7dylVXVvVd0JrAa+0NpXAUOj1Ny/JXsxsGur6Xvt/DnAgX39L4Deqhl4DvDp9jV/BJjX+nwLODvJHwKdtm6ramlVLaqqRXO2ndvlEknSJBjoe5jAzsCWrNtKfTWwE7BPO///gLWrwof7rl9Db0UXoEa5R0ZpHznWo32vH6X75+tuaHyA+9vvjwHu6QvbhVW1O0BVvQF4J/BUYHmSJ3a8tyRpmg10S7aqVgNvBd6e5LHAXOCOqnqkvee48xjX3wOsTnJAa3p13+kr1r5Osgvw68BNk1j+jfRWuU9vr38fuHxkp6r6GXBLkle0WpJk73b8tKq6uqreBdxFLzjvBbafxDolSZNg4A/9VNV1wArgKOCfgEVJhumF3Y0dhngt8MH20M+Dfe0fAuYkWUVve/S4qnp4fQNMsO6H2r0/3e7xKHDmKN1fDbw+yQrgBuDw1n5qe2DoenoBvwK4FHiGD/1I0sySqtF2NDXTbTVvQc079rRBlyHNWv54r81TkmVVtWi81w18hSlJ0mxgYEqS1IGBKUlSBwamJEkddP2eQ81Ae82fy7APLUjStHCFKUlSBwamJEkdGJiSJHVgYEqS1IEP/cxiq25fzdCSiwZdhjTt/IQeDYIrTEmSOjAwJUnqwMCUJKkDA1OSpA4MTEmSOjAwJUnqYNYHZpI1SZYnWZHk2iTPGaP/Dkne1Pd6KMmrNrKGq1sNP0pyZztenmRoY8aVJM0csz4wgQeramFV7Q28Azh5jP47AG/qez0EjCswk8zpf11Vv1VVC4F3ARe0ehZW1a0buk6SNHtsCoHZ73HA3WtfJDkhyTVJVib569Z8CvC0tgI8tb1+bnv9tiRzkpzad91/a2MdlOTSJOcBq7oUk2SLJPckOSnJd4DFSfZNcnmSZUm+nOTJre+CJBe39iuS7DKJ8yJJ2kibwif9bJNkObA1MA94PkCSQ4EFwGIgwIVJDgSWAHu2FSFJDgLeXlUvba+PB1ZX1b5JtgK+leSSdq/F7dpbxlHfXODaqnpnG+9S4LCquivJq4G/AY4HlgJ/UFU/SPLbwBnAoSMHa/UdDzDncTuNowxJ0sbYFALzwb7w2x84N8me9MLmUOC61m87egH6ozHGOxR4ZpIj2+u57bqfA98ZZ1jSrvtsO94d2AP4WhKAOcBtSXYA9gM+09phlD+bqlpKL1zZat6CGmctkqQJ2hQC85eq6sokOwI70VtVnlxVH+nv0+FBnABvqaqLR1x3EHD/BMp6sKrWBluAlVX13BFjPx64a23wS5Jmnk3qPcwku9Fbtf0EuBh4XZLt2rn5SZ4E3Ats33fZyNcXA29M8th23S5JfmWSSvwuMD/J4jb2lkn2qKq7gX9PckRrf0ySvSfpnpKkSbAprDDXvocJvRXcsVW1Brgkye7AlW2b8z7gmPYe4beSXA98GfhL4BdJVgBnAx+g9+TsteldeCfwsskotKoeblu9pyfZnt78vx+4ATgK+HCSE4EtgU8CKybjvpKkjZd1u4Wabbaat6DmHXvaoMuQpp0/3ksbI8myqlo03us2qS1ZSZKmioEpSVIHBqYkSR0YmJIkdWBgSpLUwabwbSWbrb3mz2XYpwUlaVq4wpQkqQMDU5KkDgxMSZI6MDAlSerAh35msVW3r2ZoyUWDLkOaVfxYPU2UK0xJkjowMCVJ6sDAlCSpAwNTkqQODExJkjowMCVJ6mBWBmaSv0pyQ5KVSZYn+a3W/rEkz5ike9w3jr5Xtzp+lOTOdrw8ydBk1CJJGrxZ932YSfYHXgo8u6oeTrIjsCVAVf3BIGqqqrWBfRywqKrevL5+SeZU1ZrprE2SNDlm4wpzHnBXVT0MUFV3VdWPAZJclmRRO74vyd8lWZbka0kWt/M3Jzms9TkuyeeTfCXJTUnevb4bJjkhyTVtRfvXXQtNskWSe5KclOQ7wOIk+ya5vNX15SRPbn0XJLm4tV+RZJeNmyZJ0mSajYF5CfDUJN9L8qEkzxul368Al1XVPsC9wEnAC4AjgPf09VsMvBpYCLxibeCuleRQYEHrtxDYJ8mB46h3LnBtVS0GrgU+ALy81fVJ4G9av6XAm1r7O4Az1jdYkuOTDCcZXvPA6nGUIUnaGLNuS7aq7kuyD/Bc4GDggiRLqursEV1/DnylHa8CHq6qR5KsAob6+n21qn4CkORfgAOA4b7zh7Zf17XX29EL0Cs6lvxz4LPteHdgD+BrSQDmALcl2QHYD/hMa4dR/myqaim9cGWreQuqYw2SpI006wIToL0PeBlwWQvAY4GzR3R7pKrWBsqjwNot3EeT9H/dI0Nn5OsAJ1fVRyZY7oN9dQRYWVXP/Q83SB5Pb5t54QTvIUmaYrNuSzbJrkkW9DUtBH64EUO+IMkTkmwDvAz41ojzFwOvS7Jdu//8JE+a4L2+C8xPsriNtWWSParqbuDfkxzR2h+TZO8J3kOSNAVm4wpzO+Af2jbmL4DvA8dvxHjfBD4BPB04r6r6t2OpqkuS7A5c2bZL7wOOAe4Y743aU71HAqcn2Z7e/L8fuAE4CvhwkhPpPfX7SWDFRL8oSdLkyrrdws3PWN8GMtNtNW9BzTv2tEGXIc0q/ngvJVlWVYvG7vkfzbotWUmSBmE2bslOmvZk7dkDLkOSNAu4wpQkqQMDU5KkDjbrLdnZbq/5cxn2AQZJmhauMCVJ6sDAlCSpAwNTkqQODExJkjowMCVJ6sDAlCSpAwNTkqQODExJkjowMCVJ6mCz/vFes12Se4GbBl3HDLEjcNegi5ghnIt1nIt1nIt1dq2q7cd7kR+NN7vdNJGf6bYpSjLsXPQ4F+s4F+s4F+skGZ7IdW7JSpLUgYEpSVIHBubstnTQBcwgzsU6zsU6zsU6zsU6E5oLH/qRJKkDV5iSJHVgYEqS1IGBOQskeVGSm5J8P8mS9ZzfKskF7fzVSYamv8rp0WEu/jTJd5OsTPL1JDsPos7pMNZc9PU7Mkkl2WS/paDLXCT5r+3vxg1JzpvuGqdLh38jv57k0iTXtX8nLx5EnVMtyVlJ7khy/Sjnk+T0Nk8rkzx7zEGryl8z+BcwB/gB8JvAlsAK4Bkj+rwJOLMdHwVcMOi6BzgXBwPbtuM3bs5z0fptD1wBXAUsGnTdA/x7sQC4Dnh8e/2kQdc9wLlYCryxHT8DuHXQdU/RXBwIPBu4fpTzLwa+DATYD7h6rDFdYc58i4HvV9XNVfVz4Hzg8BF9DgfOacf/DBySJNNY43QZcy6q6tKqeqC9vAp4yjTXOF26/L0A+BvgfwAPTWdx06zLXPwh8MGquhugqu6Y5hqnS5e5KOBx7Xgu8ONprG/aVNUVwE830OVw4NzquQrYIcm8DY1pYM5884F/63t9W2tbb5+q+gWwGnjitFQ3vbrMRb/X0/s/yE3RmHOR5FnAU6vqi9NZ2AB0+XuxC7BLkm8luSrJi6atuunVZS5OBI5JchvwJeAt01PajDPe/5740XizwPpWiiO/F6hLn01B568zyTHAIuB5U1rR4GxwLpI8Bvh74LjpKmiAuvy92ILetuxB9HYdvpFkz6q6Z4prm25d5uJo4Oyqen+S/YFPtLl4dOrLm1HG/d9NV5gz323AU/teP4X/vIXyyz5JtqC3zbKhrYjZqstckOR3gL8CDquqh6eptuk21lxsD+wJXJbkVnrv0Vy4iT740/XfyOer6pGquoXeDy1YME31Tacuc/F64H8BVNWVwNb0Pph9c9Ppvyf9DMyZ7xpgQZLfSLIlvYd6LhzR50Lg2HZ8JPCv1d7V3sSMORdtG/Ij9MJyU32fCsaYi6paXVU7VtVQVQ3Rez/3sKqa0IdOz3Bd/o18jt4DYSTZkd4W7c3TWuX06DIXPwIOAUiyO73AvHNaq5wZLgRe056W3Q9YXVX/vqEL3JKd4arqF0neDFxM7wm4s6rqhiTvAYar6kLgH+ltq3yf3sryqMFVPHU6zsWpwHbAp9tzTz+qqsMGVvQU6TgXm4WOc3ExcGiS7wJrgBOq6ieDq3pqdJyLPwM+muRt9LYgj9sU/wc7yafobcHv2N6vfTfwWICqOpPe+7cvBr4PPAC8dswxN8F5kiRp0rklK0lSBwamJEkdGJiSJHVgYEqS1IGBKUlSBwamJEkdGJiSJHXw/wEFAFwAARKgSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Best Model On Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('fashion-mnist_test.csv')\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_dataset[test_dataset.columns[1:]]\n",
    "test_Y = np.array(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_filled</th>\n",
       "      <th>percent_filled_top</th>\n",
       "      <th>percent_filled_bottom</th>\n",
       "      <th>row_sum_0</th>\n",
       "      <th>row_sum_1</th>\n",
       "      <th>row_sum_2</th>\n",
       "      <th>row_sum_3</th>\n",
       "      <th>row_sum_4</th>\n",
       "      <th>row_sum_5</th>\n",
       "      <th>row_sum_6</th>\n",
       "      <th>...</th>\n",
       "      <th>row_sum_19</th>\n",
       "      <th>row_sum_20</th>\n",
       "      <th>row_sum_21</th>\n",
       "      <th>row_sum_22</th>\n",
       "      <th>row_sum_23</th>\n",
       "      <th>row_sum_24</th>\n",
       "      <th>row_sum_25</th>\n",
       "      <th>row_sum_26</th>\n",
       "      <th>row_sum_27</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.399620</td>\n",
       "      <td>0.422389</td>\n",
       "      <td>0.376851</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>0.078992</td>\n",
       "      <td>0.185994</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.550840</td>\n",
       "      <td>0.540196</td>\n",
       "      <td>0.518347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.391737</td>\n",
       "      <td>0.395098</td>\n",
       "      <td>0.395938</td>\n",
       "      <td>0.400560</td>\n",
       "      <td>0.393697</td>\n",
       "      <td>0.370728</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>0.212745</td>\n",
       "      <td>0.161990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210664</td>\n",
       "      <td>0.236134</td>\n",
       "      <td>0.185194</td>\n",
       "      <td>0.209664</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.291877</td>\n",
       "      <td>0.267787</td>\n",
       "      <td>0.248880</td>\n",
       "      <td>0.240756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199160</td>\n",
       "      <td>0.201821</td>\n",
       "      <td>0.199860</td>\n",
       "      <td>0.202941</td>\n",
       "      <td>0.198039</td>\n",
       "      <td>0.191317</td>\n",
       "      <td>0.185294</td>\n",
       "      <td>0.185294</td>\n",
       "      <td>0.155742</td>\n",
       "      <td>0.084184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168382</td>\n",
       "      <td>0.193377</td>\n",
       "      <td>0.143387</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>0.267507</td>\n",
       "      <td>0.189076</td>\n",
       "      <td>0.192577</td>\n",
       "      <td>0.219328</td>\n",
       "      <td>0.205462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211345</td>\n",
       "      <td>0.240196</td>\n",
       "      <td>0.157423</td>\n",
       "      <td>0.139216</td>\n",
       "      <td>0.113165</td>\n",
       "      <td>0.079272</td>\n",
       "      <td>0.072129</td>\n",
       "      <td>0.028291</td>\n",
       "      <td>0.038375</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407893</td>\n",
       "      <td>0.460554</td>\n",
       "      <td>0.355232</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.455602</td>\n",
       "      <td>0.452101</td>\n",
       "      <td>0.430532</td>\n",
       "      <td>0.433053</td>\n",
       "      <td>0.462465</td>\n",
       "      <td>0.500560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374510</td>\n",
       "      <td>0.319888</td>\n",
       "      <td>0.264146</td>\n",
       "      <td>0.236835</td>\n",
       "      <td>0.277311</td>\n",
       "      <td>0.257423</td>\n",
       "      <td>0.475070</td>\n",
       "      <td>0.725350</td>\n",
       "      <td>0.445798</td>\n",
       "      <td>0.103316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.252716</td>\n",
       "      <td>0.325090</td>\n",
       "      <td>0.180342</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.281092</td>\n",
       "      <td>0.360924</td>\n",
       "      <td>0.362745</td>\n",
       "      <td>0.369328</td>\n",
       "      <td>0.381933</td>\n",
       "      <td>0.343277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251261</td>\n",
       "      <td>0.259664</td>\n",
       "      <td>0.216527</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>0.026751</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.079082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.270638</td>\n",
       "      <td>0.251210</td>\n",
       "      <td>0.290066</td>\n",
       "      <td>0.047479</td>\n",
       "      <td>0.181513</td>\n",
       "      <td>0.237255</td>\n",
       "      <td>0.223389</td>\n",
       "      <td>0.230952</td>\n",
       "      <td>0.228011</td>\n",
       "      <td>0.247899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271849</td>\n",
       "      <td>0.238515</td>\n",
       "      <td>0.256162</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.272829</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.298599</td>\n",
       "      <td>0.286975</td>\n",
       "      <td>0.188375</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.404432</td>\n",
       "      <td>0.368958</td>\n",
       "      <td>0.439906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780532</td>\n",
       "      <td>0.792997</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.123950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.290756</td>\n",
       "      <td>0.255282</td>\n",
       "      <td>0.326230</td>\n",
       "      <td>0.045238</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.236835</td>\n",
       "      <td>0.185854</td>\n",
       "      <td>0.223389</td>\n",
       "      <td>0.243417</td>\n",
       "      <td>0.255462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346359</td>\n",
       "      <td>0.344398</td>\n",
       "      <td>0.332773</td>\n",
       "      <td>0.324790</td>\n",
       "      <td>0.347059</td>\n",
       "      <td>0.280532</td>\n",
       "      <td>0.261485</td>\n",
       "      <td>0.311204</td>\n",
       "      <td>0.283193</td>\n",
       "      <td>0.052296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.167462</td>\n",
       "      <td>0.139776</td>\n",
       "      <td>0.195148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.163165</td>\n",
       "      <td>0.316947</td>\n",
       "      <td>0.357843</td>\n",
       "      <td>0.205042</td>\n",
       "      <td>0.085294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124790</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.178011</td>\n",
       "      <td>0.339916</td>\n",
       "      <td>0.399860</td>\n",
       "      <td>0.423249</td>\n",
       "      <td>0.176331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.215581</td>\n",
       "      <td>0.257233</td>\n",
       "      <td>0.173930</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>0.245238</td>\n",
       "      <td>0.248319</td>\n",
       "      <td>0.227731</td>\n",
       "      <td>0.203221</td>\n",
       "      <td>0.267227</td>\n",
       "      <td>0.389776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175350</td>\n",
       "      <td>0.173389</td>\n",
       "      <td>0.176611</td>\n",
       "      <td>0.185014</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>0.190616</td>\n",
       "      <td>0.192297</td>\n",
       "      <td>0.224090</td>\n",
       "      <td>0.107423</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   percent_filled  percent_filled_top  percent_filled_bottom  row_sum_0  \\\n",
       "0        0.399620            0.422389               0.376851   0.018347   \n",
       "1        0.210664            0.236134               0.185194   0.209664   \n",
       "2        0.168382            0.193377               0.143387   0.051961   \n",
       "3        0.407893            0.460554               0.355232   0.257143   \n",
       "4        0.252716            0.325090               0.180342   0.007563   \n",
       "5        0.270638            0.251210               0.290066   0.047479   \n",
       "6        0.404432            0.368958               0.439906   0.000000   \n",
       "7        0.290756            0.255282               0.326230   0.045238   \n",
       "8        0.167462            0.139776               0.195148   0.000000   \n",
       "9        0.215581            0.257233               0.173930   0.046218   \n",
       "\n",
       "   row_sum_1  row_sum_2  row_sum_3  row_sum_4  row_sum_5  row_sum_6  ...  \\\n",
       "0   0.078992   0.185994   0.414286   0.550840   0.540196   0.518347  ...   \n",
       "1   0.250000   0.267647   0.291877   0.267787   0.248880   0.240756  ...   \n",
       "2   0.157563   0.267507   0.189076   0.192577   0.219328   0.205462  ...   \n",
       "3   0.455602   0.452101   0.430532   0.433053   0.462465   0.500560  ...   \n",
       "4   0.281092   0.360924   0.362745   0.369328   0.381933   0.343277  ...   \n",
       "5   0.181513   0.237255   0.223389   0.230952   0.228011   0.247899  ...   \n",
       "6   0.000000   0.000000   0.000000   0.000000   0.000000   0.395098  ...   \n",
       "7   0.160784   0.236835   0.185854   0.223389   0.243417   0.255462  ...   \n",
       "8   0.030952   0.163165   0.316947   0.357843   0.205042   0.085294  ...   \n",
       "9   0.245238   0.248319   0.227731   0.203221   0.267227   0.389776  ...   \n",
       "\n",
       "   row_sum_19  row_sum_20  row_sum_21  row_sum_22  row_sum_23  row_sum_24  \\\n",
       "0    0.388235    0.391737    0.395098    0.395938    0.400560    0.393697   \n",
       "1    0.199160    0.201821    0.199860    0.202941    0.198039    0.191317   \n",
       "2    0.211345    0.240196    0.157423    0.139216    0.113165    0.079272   \n",
       "3    0.374510    0.319888    0.264146    0.236835    0.277311    0.257423   \n",
       "4    0.251261    0.259664    0.216527    0.034594    0.026751    0.017647   \n",
       "5    0.271849    0.238515    0.256162    0.267647    0.272829    0.282353   \n",
       "6    0.780532    0.792997    0.885714    0.123950    0.000000    0.000000   \n",
       "7    0.346359    0.344398    0.332773    0.324790    0.347059    0.280532   \n",
       "8    0.124790    0.178571    0.183333    0.178011    0.339916    0.399860   \n",
       "9    0.175350    0.173389    0.176611    0.185014    0.180952    0.190616   \n",
       "\n",
       "   row_sum_25  row_sum_26  row_sum_27  symmetry  \n",
       "0    0.370728    0.457843    0.212745  0.161990  \n",
       "1    0.185294    0.185294    0.155742  0.084184  \n",
       "2    0.072129    0.028291    0.038375  0.010204  \n",
       "3    0.475070    0.725350    0.445798  0.103316  \n",
       "4    0.016387    0.010364    0.010364  0.079082  \n",
       "5    0.298599    0.286975    0.188375  0.010204  \n",
       "6    0.000000    0.000000    0.000000  0.202806  \n",
       "7    0.261485    0.311204    0.283193  0.052296  \n",
       "8    0.423249    0.176331    0.000000  0.033163  \n",
       "9    0.192297    0.224090    0.107423  0.000000  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engineered_features_test = pd.DataFrame()\n",
    "\n",
    "# Calcualte percentage of filled pixels and a top and bottom half only version\n",
    "percent_filled = test_X.sum(axis = 1)/(28*28)\n",
    "percent_filled_top = test_X.iloc[:, 0:392].sum(axis = 1)/(28*14)\n",
    "percent_filled_bottom = test_X.iloc[:, 392:784].sum(axis = 1)/(28*14)\n",
    "engineered_features_test['percent_filled'] = percent_filled\n",
    "engineered_features_test['percent_filled_top'] = percent_filled_top\n",
    "engineered_features_test['percent_filled_bottom'] = percent_filled_bottom\n",
    "\n",
    "# Calculate the sum of each row\n",
    "for idx, i in enumerate(range(0, 784, 28)):\n",
    "    row_sum = test_X.iloc[:, i:(i + 28)].sum(axis = 1)/28\n",
    "    engineered_features_test[\"row_sum_\" + str(idx)] = row_sum\n",
    "\n",
    "# Calcualte a measure of syymmetry around a horizontal axis\n",
    "s1 = np.round(np.array(test_X.iloc[:, 0:392]))\n",
    "s2 = np.round(np.array(test_X.iloc[:, 784:391:-1]))\n",
    "s3 = np.logical_and(s1, s2).astype(int)\n",
    "symmetry = s3.sum(axis = 1)/(28*28)\n",
    "\n",
    "engineered_features_test['symmetry'] = symmetry\n",
    "\n",
    "display(engineered_features_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = engineered_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = linear_model.LogisticRegression(C=0.4,max_iter = 1000,multi_class='ovr',solver='liblinear')\n",
    "my_model = my_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63      1000\n",
      "           1       0.64      0.90      0.75      1000\n",
      "           2       0.50      0.54      0.52      1000\n",
      "           3       0.51      0.56      0.54      1000\n",
      "           4       0.51      0.51      0.51      1000\n",
      "           5       0.61      0.66      0.63      1000\n",
      "           6       0.42      0.16      0.23      1000\n",
      "           7       0.76      0.79      0.77      1000\n",
      "           8       0.74      0.69      0.72      1000\n",
      "           9       0.71      0.74      0.72      1000\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.60      0.62      0.60     10000\n",
      "weighted avg       0.60      0.62      0.60     10000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604</td>\n",
       "      <td>142</td>\n",
       "      <td>32</td>\n",
       "      <td>114</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>901</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>94</td>\n",
       "      <td>543</td>\n",
       "      <td>56</td>\n",
       "      <td>173</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>124</td>\n",
       "      <td>69</td>\n",
       "      <td>565</td>\n",
       "      <td>23</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>212</td>\n",
       "      <td>55</td>\n",
       "      <td>507</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>659</td>\n",
       "      <td>9</td>\n",
       "      <td>144</td>\n",
       "      <td>8</td>\n",
       "      <td>109</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "      <td>96</td>\n",
       "      <td>128</td>\n",
       "      <td>153</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>787</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>692</td>\n",
       "      <td>85</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>20</td>\n",
       "      <td>69</td>\n",
       "      <td>37</td>\n",
       "      <td>739</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>931</td>\n",
       "      <td>1407</td>\n",
       "      <td>1083</td>\n",
       "      <td>1103</td>\n",
       "      <td>995</td>\n",
       "      <td>1082</td>\n",
       "      <td>381</td>\n",
       "      <td>1042</td>\n",
       "      <td>932</td>\n",
       "      <td>1044</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0     1     2     3    4     5    6     7    8     9    All\n",
       "True                                                                    \n",
       "0          604   142    32   114   28    15   24     1   37     3   1000\n",
       "1           30   901    21    36    5     4    2     0    1     0   1000\n",
       "2           29    94   543    56  173    19   57     0   21     8   1000\n",
       "3           97   124    69   565   23    70   37     0   13     2   1000\n",
       "4           11    46   212    55  507    17   65     0   81     6   1000\n",
       "5            4     3     3    59    2   659    9   144    8   109   1000\n",
       "6          147    96   128   153  200    64  160     0   40    12   1000\n",
       "7            0     0     0     0    0   131    0   787    2    80   1000\n",
       "8            9     1    22    40   47    56    7    41  692    85   1000\n",
       "9            0     0    53    25   10    47   20    69   37   739   1000\n",
       "All        931  1407  1083  1103  995  1082  381  1042  932  1044  10000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(test_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_Y, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(test_Y), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
